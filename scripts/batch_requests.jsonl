{"custom_id": "package:5:econml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: EconML\nDescription: Microsoft toolkit for estimating heterogeneous treatment effects using DML, causal forests, meta-learners, and orthogonal ML methods.\nCategory: Double/Debiased Machine Learning (DML)\nLanguage: Python\nTags: machine learning, causal inference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:6:econml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: EconML\nDescription: Microsoft's package for ML-based causal inference. Double ML, causal forests, instrumental variables, and dynamic treatment regimes. Strong theoretical foundations.\nCategory: Healthcare Economics & Health-Tech\nLanguage: Python\nTags: causal inference, double ML, causal forests\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:7:econml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: EconML\nDescription: Microsoft's library for heterogeneous treatment effects with Double ML, Causal Forests, and DRLearner\nCategory: Causal Inference\nLanguage: Python\nTags: Double ML, Causal Forest, CATE, Microsoft\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:25:pymc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: PyMC\nDescription: Flexible probabilistic programming library for Bayesian modeling and inference using MCMC algorithms (NUTS).\nCategory: Bayesian Econometrics\nLanguage: Python\nTags: Bayesian, inference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:31:dowhy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: DoWhy\nDescription: End-to-end framework for causal inference based on causal graphs (DAGs) and potential outcomes. Covers identification, estimation, refutation.\nCategory: Causal Inference & Matching\nLanguage: Python\nTags: causal inference, matching\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:56:causalml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CausalML\nDescription: Uber's package for uplift modeling and causal inference. Includes meta-learners (S, T, X, R), tree-based methods, and propensity score approaches. Focus on heterogeneous treatment effects.\nCategory: Healthcare Economics & Health-Tech\nLanguage: Python\nTags: causal inference, uplift modeling, treatment effects\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:57:causalml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CausalML\nDescription: Uber's Python library for uplift modeling and causal inference with meta-learners, uplift trees, and propensity methods\nCategory: Causal Inference\nLanguage: Python\nTags: uplift modeling, CATE, meta-learners, treatment effects\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:58:causalml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CausalML\nDescription: Uber's library for uplift modeling and heterogeneous treatment effect estimation. Implements meta-learners (S, T, X, R, DR), uplift trees, and CATE estimation for targeting optimization.\nCategory: MarTech & Customer Analytics\nLanguage: Python\nTags: uplift, causal-inference, targeting, treatment-effects\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:69:prophet", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Prophet\nDescription: Facebook/Meta's time series forecasting with trend, seasonality, and holiday effects. Excellent for electricity load forecasting with automatic changepoint detection.\nCategory: Energy & Utilities Economics\nLanguage: Python/R\nTags: forecasting, time series, load forecasting\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:77:edsl", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: EDSL\nDescription: Expected Parrot Domain-Specific Language for designing and running LLM-powered surveys and experiments. Create AI agent personas with demographic traits for homo silicus research.\nCategory: Agentic AI\nLanguage: Python\nTags: LLM, surveys, experiments, homo-silicus, synthetic-agents\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:78:anthropic", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: anthropic\nDescription: Official Python SDK for Claude and Anthropic's API. Build AI applications with Claude models.\nCategory: Agentic AI\nLanguage: Python\nTags: LLM, Claude, API, Anthropic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:79:openai", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: openai\nDescription: Official Python SDK for OpenAI's API. Access GPT-4, o1, DALL-E, embeddings, and other OpenAI models.\nCategory: Agentic AI\nLanguage: Python\nTags: LLM, GPT, API, OpenAI, embeddings\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:81:dolo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Dolo\nDescription: Rational expectations and DSGE model solver using YAML model definitions. Part of the EconForge ecosystem with Julia companion.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: DSGE, rational-expectations, macroeconomics, dynamic-programming\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:101:lifelines", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: lifelines\nDescription: Comprehensive library for survival analysis: Kaplan-Meier, Nelson-Aalen, Cox regression, AFT models, handling censored data.\nCategory: Statistical Inference & Hypothesis Testing\nLanguage: Python\nTags: inference, hypothesis testing\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:103:lifelines", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: lifelines\nDescription: Pure Python survival analysis library. Kaplan-Meier estimation, Cox PH regression, parametric models (Weibull, log-normal), and time-varying covariates. Excellent documentation.\nCategory: Healthcare Economics & Health-Tech\nLanguage: Python\nTags: survival analysis, Kaplan-Meier, Cox regression\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:134:lightgbm", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: LightGBM\nDescription: Microsoft's fast gradient boosting with histogram-based algorithm, widely used in ad tech for CTR prediction\nCategory: Machine Learning\nLanguage: Python\nTags: gradient boosting, fast, categorical, Microsoft\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:141:highs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: HiGHS\nDescription: High-performance open-source linear and mixed-integer programming solver\nCategory: Optimization\nLanguage: Python\nTags: solver, LP, MIP, optimization, open-source\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:144:py-econometrics-gmm", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: py-econometrics `gmm`\nDescription: Lightweight package for setting up and estimating custom GMM models based on user-defined moment conditions.\nCategory: Instrumental Variables\nLanguage: Python\nTags: IV, GMM\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:166:causalpy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CausalPy\nDescription: Bayesian causal inference on PyMC including synthetic control, difference-in-differences, and regression discontinuity.\nCategory: Causal Inference (Synthetic Control)\nLanguage: Python\nTags: causal-inference, Bayesian, synthetic-control, DiD, RDD, PyMC\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:176:pymc-marketing", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: PyMC-Marketing\nDescription: Bayesian marketing analytics toolkit from PyMC Labs. Combines Marketing Mix Modeling, CLV estimation, and discrete choice models with full uncertainty quantification and GPU acceleration.\nCategory: MarTech & Customer Analytics\nLanguage: Python\nTags: CLV, MMM, Bayesian, marketing-analytics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:186:biogeme", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Biogeme\nDescription: The reference Python package for discrete choice model estimation (logit, nested logit, mixed logit). Developed by Michel Bierlaire at EPFL, widely used in transportation research.\nCategory: Transportation Economics & Technology\nLanguage: Python\nTags: discrete choice, logit, transportation, mode choice\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:207:microsynth", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: microsynth\nDescription: Micro-level synthetic control with permutation-based inference. Extends synthetic control to individual-level data.\nCategory: Causal Inference (Synthetic Control)\nLanguage: R\nTags: synthetic-control, causal-inference, permutation-test, micro-data\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:219:pyomo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Pyomo\nDescription: Python-based open-source optimization modeling language supporting linear, mixed-integer, nonlinear programming\nCategory: Optimization\nLanguage: Python\nTags: optimization, linear programming, MILP, nonlinear\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:222:opendss", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: OpenDSS\nDescription: Electric power distribution system simulator for distributed energy resources and smart grid\nCategory: Energy Systems Modeling\nLanguage: Python\nTags: distribution, DER, smart grid, EPRI\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:225:pandapower", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: pandapower\nDescription: Easy-to-use Python library for power system modeling, analysis, and optimization\nCategory: Energy Systems Modeling\nLanguage: Python\nTags: power flow, short circuit, optimal power flow, distribution\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:236:catalystcoop-pudl", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: catalystcoop-pudl\nDescription: Public Utility Data Liberation - integrated energy data from EIA, FERC, and EPA\nCategory: Data Access\nLanguage: Python\nTags: EIA, FERC, EPA, integrated data, ETL\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:239:pylogit", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: PyLogit\nDescription: Sklearn-style API for discrete choice models (MNL, nested, mixed logit). Integrates well with pandas DataFrames and scikit-learn workflows.\nCategory: Transportation Economics & Technology\nLanguage: Python\nTags: discrete choice, logit, sklearn, pandas\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:262:eiapy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: eiapy\nDescription: Python wrapper for the U.S. Energy Information Administration (EIA) API\nCategory: Data Access\nLanguage: Python\nTags: EIA, API, energy data, government data\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:268:causalimpact", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CausalImpact\nDescription: Google's Bayesian structural time-series package for measuring intervention effects on time series\nCategory: Causal Inference\nLanguage: R\nTags: time series, Bayesian, intervention, Google\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:290:genx", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: GenX\nDescription: Julia-based capacity expansion model for electricity systems with detailed operational constraints\nCategory: Energy Systems Modeling\nLanguage: Julia\nTags: capacity expansion, Julia, electricity planning, decarbonization\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:295:scikit-survival", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: scikit-survival\nDescription: Survival analysis compatible with scikit-learn. Includes Cox proportional hazards, random survival forests, gradient boosting survival, and evaluation metrics (C-index, Brier score).\nCategory: Healthcare Economics & Health-Tech\nLanguage: Python\nTags: survival analysis, machine learning, clinical prediction\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:296:ruspy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: ruspy\nDescription: Python package for simulation and estimation of Rust (1987) bus engine replacement model. Implements the nested fixed point (NFXP) algorithm for dynamic discrete choice. The reference implementation for learning structural estimation.\nCategory: Structural Econometrics & Estimation\nLanguage: Python\nTags: structural estimation, dynamic discrete choice, econometrics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:325:igraph", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: igraph\nDescription: Network analysis and visualization library for R and Python, applicable to defense supply chains and alliance networks\nCategory: Network Analysis\nLanguage: R\nTags: networks, graphs, visualization, analysis\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:339:survival", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: survival\nDescription: Core survival analysis package in R. Kaplan-Meier, Cox regression, parametric models, and diagnostic tools. Foundation for most R survival packages.\nCategory: Healthcare Economics & Health-Tech\nLanguage: R\nTags: survival analysis, Cox regression, Kaplan-Meier, R\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:355:pypsa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: PyPSA\nDescription: Python for Power System Analysis - open-source toolbox for simulating and optimizing power systems\nCategory: Energy Systems Modeling\nLanguage: Python\nTags: power systems, optimization, grid modeling, renewable integration\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:397:surprise", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Surprise\nDescription: Scikit-learn-style library for building and analyzing recommender systems. Implements SVD, SVD++, NMF, KNN, and baseline algorithms with built-in cross-validation and hyperparameter search.\nCategory: MarTech & Customer Analytics\nLanguage: Python\nTags: recommendations, collaborative-filtering, matrix-factorization\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:400:powermodels-jl", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: PowerModels.jl\nDescription: Julia/JuMP package for power flow and optimal power flow problems\nCategory: Energy Systems Modeling\nLanguage: Julia\nTags: power flow, optimal power flow, Julia, JuMP\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:404:sf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: sf\nDescription: R package for simple features geospatial data handling, useful for military installation mapping and conflict geography\nCategory: Geospatial\nLanguage: R\nTags: geospatial, GIS, mapping, spatial analysis\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:414:xgboost", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: xgboost\nDescription: Gradient boosting framework widely used as baseline for CTR prediction and attribution modeling\nCategory: Machine Learning\nLanguage: Python\nTags: gradient boosting, CTR, baseline, XGBoost\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:421:geolift", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: GeoLift\nDescription: Meta's geo-experimental methodology combining Augmented Synthetic Control with power analysis\nCategory: Causal Inference\nLanguage: R\nTags: geo experiments, synthetic control, power analysis, Meta\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:460:nltk", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: NLTK\nDescription: Natural Language Toolkit - comprehensive library for NLP research and education with 50+ corpora and lexical resources.\nCategory: Natural Language Processing for Economics\nLanguage: Python\nTags: NLP, text-analysis, corpora, tokenization\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:461:sentence-transformers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: sentence-transformers\nDescription: Framework for state-of-the-art sentence, text and image embeddings. Powers semantic search and similarity applications.\nCategory: Natural Language Processing for Economics\nLanguage: Python\nTags: embeddings, semantic-search, NLP, transformers\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:462:tensorflow", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: TensorFlow\nDescription: Google's end-to-end open-source machine learning platform. Build and deploy ML models at scale.\nCategory: Machine Learning\nLanguage: Python\nTags: deep-learning, neural-networks, machine-learning, Google\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:463:elicit", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Elicit\nDescription: AI research assistant that automates literature review across 126M+ academic papers. 99%+ accuracy in data extraction from research papers.\nCategory: Research Tools\nLanguage: Web\nTags: literature-review, research, AI-assistant, academic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:464:consensus", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Consensus\nDescription: AI-powered academic search engine providing evidence-based answers from peer-reviewed literature with economics specialty.\nCategory: Research Tools\nLanguage: Web\nTags: literature-review, research, evidence-based, academic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:465:semantic-scholar-api", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Semantic Scholar API\nDescription: AI-powered research tool with 200M+ papers indexed. Free API access for academic paper search and citation analysis.\nCategory: Research Tools\nLanguage: Python\nTags: literature-review, API, citations, academic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:466:research-rabbit", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Research Rabbit\nDescription: Free tool for discovering academic papers through network visualization of paper connections and co-authorships.\nCategory: Research Tools\nLanguage: Web\nTags: literature-review, visualization, discovery, academic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:467:connected-papers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Connected Papers\nDescription: Visual tool for exploring academic paper relationships. Creates visual graphs showing prior and derivative works.\nCategory: Research Tools\nLanguage: Web\nTags: literature-review, visualization, citations, academic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:468:mesa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Mesa\nDescription: Leading open-source Python framework for agent-based modeling with spatial grids, agent schedulers, and Solara visualization. Mesa 3 (2025) requires Python 3.12+.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: agent-based-modeling, simulation, ABM, multi-agent, complexity\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:469:agentpy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: AgentPy\nDescription: Modern Python framework for agent-based modeling integrating model design with SALib sensitivity analysis and NetworkX network structures.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: agent-based-modeling, simulation, sensitivity-analysis, networks\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:470:abce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: ABCE\nDescription: Agent-Based Computational Economics library from Oxford INET. Automatically handles trade with physically consistent goods, includes built-in Firm/Household archetypes.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: agent-based-modeling, economics, trade, macroeconomics, Oxford-INET\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:471:pynetlogo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: pyNetLogo\nDescription: Python-NetLogo interface enabling SALib sensitivity analysis integration and parallel NetLogo simulations. Published in JASSS (2018).\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: NetLogo, agent-based-modeling, sensitivity-analysis, simulation\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:472:netlogor", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: NetLogoR\nDescription: Pure R implementation of NetLogo framework\u2014no NetLogo installation required. Benefits from ggplot2 integration and R spatial objects.\nCategory: Simulation & Computational Economics\nLanguage: R\nTags: NetLogo, agent-based-modeling, R, spatial-modeling\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:473:rnetlogo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: RNetLogo\nDescription: Embeds NetLogo into R for statistical analysis integration. Enables running NetLogo models and analyzing results in R environment.\nCategory: Simulation & Computational Economics\nLanguage: R\nTags: NetLogo, agent-based-modeling, R, integration\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:474:nlrx", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: nlrx\nDescription: rOpenSci package for NetLogo simulation via XML with BehaviorSpace support. Enables systematic NetLogo experiments from R.\nCategory: Simulation & Computational Economics\nLanguage: R\nTags: NetLogo, agent-based-modeling, R, experiment-design, rOpenSci\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:475:gymnasium", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Gymnasium\nDescription: Farama Foundation's successor to OpenAI Gym. Standard single-agent reinforcement learning API for environment development and benchmarking.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: reinforcement-learning, environments, RL, OpenAI-Gym, benchmarking\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:476:stable-baselines3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Stable-Baselines3\nDescription: Reliable PyTorch implementations of A2C, DDPG, DQN, PPO, SAC, TD3 RL algorithms. Published in JMLR 2021.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: reinforcement-learning, PyTorch, PPO, DQN, SAC, algorithms\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:477:rllib", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: RLlib\nDescription: Industry-grade scalable reinforcement learning library from Ray. Native multi-agent support for distributed training at scale.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: reinforcement-learning, distributed, multi-agent, scalable, Ray\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:478:cleanrl", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CleanRL\nDescription: Single-file RL algorithm implementations (~340 lines each) for educational purposes and research. Published in JMLR 2022.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: reinforcement-learning, educational, single-file, reproducible\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:479:torchrl", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: TorchRL\nDescription: Official PyTorch reinforcement learning library with TensorDict abstraction for modular RL development.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: reinforcement-learning, PyTorch, modular, TensorDict\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:480:pettingzoo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: PettingZoo\nDescription: Multi-agent version of Gymnasium with Agent-Environment-Cycle (AEC) model. Includes card games, MPE, and cooperative environments. NeurIPS 2021.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: multi-agent-RL, environments, games, cooperative, competitive\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:481:supersuit", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: SuperSuit\nDescription: Wrapper library for PettingZoo preprocessing including frame stacking, normalization, and action masking.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: multi-agent-RL, preprocessing, wrappers, PettingZoo\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:482:mo-gymnasium", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: MO-Gymnasium\nDescription: Multi-objective reinforcement learning environments for Pareto-optimal policy learning with conflicting objectives.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: multi-objective, reinforcement-learning, Pareto, trade-offs\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:483:ai-economist", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: AI Economist\nDescription: Salesforce's two-level RL environment for tax policy design. Published in Science Advances 2022. Includes COVID-19 economic simulation.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: economic-simulation, tax-policy, multi-agent, mechanism-design, Salesforce\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:484:finrl", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: FinRL\nDescription: First open-source deep reinforcement learning framework for quantitative finance. Train-test-trade pipeline for NASDAQ, DJIA, S&P 500.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: finance, trading, reinforcement-learning, quantitative, portfolio\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:485:or-gym", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: OR-Gym\nDescription: Operations research environments for RL including knapsack, bin packing, supply chain, newsvendor, and portfolio optimization.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: operations-research, inventory, supply-chain, optimization, newsvendor\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:486:mbt-gym", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: mbt_gym\nDescription: Model-based trading environments for market-making and optimal execution RL. Implements Avellaneda-Stoikov and Cartea-Jaimungal models.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: market-making, trading, high-frequency, optimal-execution, reinforcement-learning\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:487:abides", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: ABIDES\nDescription: JPMorgan's agent-based interactive discrete event simulation for market microstructure research. NASDAQ-like exchange with multiple agent types.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: market-simulation, order-book, agent-based, microstructure, JPMorgan\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:488:auctiongym", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: AuctionGym\nDescription: Amazon's ad auction simulator for first/second-price auctions with RL bidding agents. Best Paper at AdKDD 2022.\nCategory: Simulation & Computational Economics\nLanguage: Python\nTags: auction-simulation, mechanism-design, advertising, bidding, Amazon\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:489:matchingr", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: matchingR\nDescription: R/C++ implementation of Gale-Shapley and Irving's algorithms for stable matching. Tested with 30,000+ participants.\nCategory: Matching & Market Design\nLanguage: R\nTags: matching, Gale-Shapley, stable-matching, market-design\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:490:gale-shapley", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: gale-shapley\nDescription: Python O(n\u00b2) implementation of Gale-Shapley algorithm for stable matching with simulation capabilities.\nCategory: Matching & Market Design\nLanguage: Python\nTags: matching, Gale-Shapley, stable-matching, algorithm\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:491:ctgan", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: CTGAN\nDescription: GAN-based tabular data synthesizer using Variational GMM for mode-specific normalization. Published at NeurIPS 2019. Core component of SDV ecosystem.\nCategory: Synthetic Data Generation\nLanguage: Python\nTags: synthetic-data, GAN, tabular, privacy, deep-learning\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:492:deepecho", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: DeepEcho\nDescription: Time series synthetic data generation using deep learning. Part of the SDV ecosystem for sequential data.\nCategory: Synthetic Data Generation\nLanguage: Python\nTags: synthetic-data, time-series, sequential, deep-learning\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:493:faker", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Faker\nDescription: Comprehensive fake data generator for 50+ locales including names, addresses, financial data, and more. Most popular Python library for test data generation.\nCategory: Synthetic Data Generation\nLanguage: Python\nTags: synthetic-data, test-data, fake-data, localization, testing\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:494:mimesis", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Mimesis\nDescription: High-performance fake data generator\u2014faster than Faker. Provides data for multiple domains and 35+ locales.\nCategory: Synthetic Data Generation\nLanguage: Python\nTags: synthetic-data, fake-data, high-performance, localization\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:495:gretel-synthetics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Gretel Synthetics\nDescription: Open-source synthetic data library with DGAN for time series, ACTGAN, and differential privacy support from Gretel.ai.\nCategory: Synthetic Data Generation\nLanguage: Python\nTags: synthetic-data, differential-privacy, time-series, ACTGAN\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:496:datasynthesizer", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: DataSynthesizer\nDescription: Privacy-preserving synthetic data using Bayesian networks with differential privacy. From University of Washington DataResponsibly project.\nCategory: Synthetic Data Generation\nLanguage: Python\nTags: synthetic-data, differential-privacy, Bayesian-networks, privacy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:497:sdcmicro", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: sdcMicro\nDescription: Statistical Disclosure Control for microdata used by World Bank and census agencies. Comprehensive anonymization toolkit.\nCategory: Synthetic Data Generation\nLanguage: R\nTags: statistical-disclosure-control, privacy, anonymization, census\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:498:simpop", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: simPop\nDescription: Synthetic population simulation for EU-SILC style survey data. Creates realistic household and individual-level synthetic populations.\nCategory: Synthetic Data Generation\nLanguage: R\nTags: synthetic-population, survey-data, microsimulation, EU-SILC\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:499:simchef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: simChef\nDescription: DGP (Data Generating Process) framework for systematic simulation studies. Enables reproducible computational experiments.\nCategory: Power Simulation & Design of Experiments\nLanguage: R\nTags: simulation, DGP, experiments, reproducibility, statistics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:500:superpower", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: Superpower\nDescription: Simulation-based power analysis for factorial ANOVA designs (up to 3 factors). Includes Shiny app for interactive power analysis.\nCategory: Power Simulation & Design of Experiments\nLanguage: R\nTags: power-analysis, ANOVA, simulation, factorial-design\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:501:mlpwr", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: mlpwr\nDescription: Machine learning-based power analysis using surrogate models. Efficient sample size planning for complex study designs.\nCategory: Power Simulation & Design of Experiments\nLanguage: R\nTags: power-analysis, machine-learning, sample-size, simulation\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:502:recombinator", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: recombinator\nDescription: Block bootstrap methods including Moving Block, Circular Block, Stationary, and Tapered Block Bootstrap for time series.\nCategory: Bootstrap & Inference\nLanguage: Python\nTags: bootstrap, time-series, block-bootstrap, resampling\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "package:503:bootur", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching software package metadata for tech-econ.org.\n\nPACKAGE:\nName: bootUR\nDescription: Bootstrap unit root tests with sieve and wild bootstrap methods for time series stationarity testing.\nCategory: Bootstrap & Inference\nLanguage: R\nTags: bootstrap, unit-root, time-series, stationarity\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-pandas\", \"scikit-learn-basics\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"time-series\", \"bayesian\", etc.],\n  \"summary\": \"2-3 sentences: What does this package do? Who uses it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this package\"],\n  \"use_cases\": [\"2-4 specific scenarios\"],\n  \"primary_use_cases\": [\"causal forest estimation\", \"A/B test analysis\", etc.],\n  \"api_complexity\": \"simple|intermediate|advanced\",\n  \"framework_compatibility\": [\"Only include if explicitly mentioned or obvious from description\"],\n  \"implements_paper\": \"Author (Year) only if clearly documented, else null\",\n  \"related_packages\": [\"Only well-known similar packages you're confident exist\"],\n  \"maintenance_status\": \"active|stable|unmaintained\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- PRIMARY_USE_CASES: Specific tasks inferred from description\n- IMPLEMENTS_PAPER: Only if package explicitly mentions implementing a paper\n- RELATED_PACKAGES: Only include packages you're certain exist\n- SYNTHETIC_QUESTIONS: \"python library for X\", \"how to do Y in python\"\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PACKAGE/LIBRARY, include:\n- Core functionality and main features\n- API design philosophy (object-oriented, functional, declarative)\n- Key classes, functions, or modules\n- Installation and basic usage patterns\n- Comparison to alternative approaches (without inventing names)\n- Performance characteristics and scalability\n- Integration with data science workflows\n- Common pitfalls and best practices\n- When to use vs when NOT to use this package\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:0:jd-com-2020-msom-20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: JD.com 2020 (MSOM-20)\nDescription: 2.5M customers (457k purchasers) and 31,868 SKUs from JD.com\nCategory: E-Commerce\nTags: customers, SKUs, INFORMS, operations\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:26:yahoo-a1-search-advertising-dataset", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Yahoo A1 Search Advertising Dataset\nDescription: Search advertising competition dataset with sponsored search auction features and click outcomes\nCategory: Advertising\nTags: search advertising, sponsored search, Yahoo, auctions\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:66:outbrain-click-prediction-dataset", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Outbrain Click Prediction Dataset\nDescription: Content recommendation dataset with 2 billion page views and user engagement data from Outbrain\nCategory: Advertising\nTags: content recommendation, native advertising, Outbrain, engagement\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:71:criteo-kaggle-ctr-dataset", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Criteo Kaggle CTR Dataset\nDescription: Standard CTR prediction benchmark with ~45 million records across 7 days, widely used for model comparison\nCategory: Advertising\nTags: CTR prediction, benchmark, Kaggle, Criteo\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:75:avazu-click-through-rate-dataset", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Avazu Click-Through Rate Dataset\nDescription: Mobile advertising dataset with 40+ million ad click records from Avazu mobile advertising platform\nCategory: Advertising\nTags: mobile ads, CTR, Kaggle, Avazu\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:76:ipinyou-rtb-dataset", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: iPinYou RTB Dataset\nDescription: Real-time bidding dataset from Chinese DSP with ~35GB of bid requests, impressions, clicks, and conversions with bidding prices\nCategory: Advertising\nTags: RTB, bidding, conversions, iPinYou\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:144:netease-music-informs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: NetEase Music (INFORMS)\nDescription: Data from NetEase Cloud Music for INFORMS competition\nCategory: Entertainment & Media\nTags: music, streaming, INFORMS, China\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:265:criteo-attribution-dataset", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Criteo Attribution Dataset\nDescription: 30 days of advertising traffic with conversion attribution data for multi-touch attribution research\nCategory: Advertising\nTags: attribution, conversions, touchpoints, Criteo\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:268:criteo-1tb-click-logs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Criteo 1TB Click Logs\nDescription: World's largest public ML advertising dataset with 4+ billion events, 13 integer and 26 categorical features across 24 days\nCategory: Advertising\nTags: CTR prediction, click logs, large-scale, Criteo\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:281:hugging-face-datasets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Hugging Face Datasets\nDescription: ML/NLP datasets hub with 100K+ datasets. Easy loading via Python library. Community-driven repository\nCategory: Data Portals\nTags: ML, NLP, datasets, Hugging Face, community\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:294:nyc-tlc-trip-records", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: NYC TLC Trip Records\nDescription: Complete trip-level data for all NYC taxi and for-hire vehicle trips including Uber and Lyft. Billions of records since 2009 with pickups, dropoffs, fares, and tips.\nCategory: Transportation Economics & Technology\nTags: taxi, rideshare, NYC, trip-data, surge-pricing\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:300:openml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: OpenML\nDescription: Platform for sharing datasets, tasks, and ML code\nCategory: Data Portals\nTags: ML, open science, benchmarks\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:302:google-dataset-search", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Google Dataset Search\nDescription: Universal search engine for datasets across the web. Meta-tool for discovering research data\nCategory: Data Portals\nTags: search engine, datasets, discovery, Google\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:335:world-bank-light-every-night", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: World Bank Light Every Night\nDescription: 30 years of nighttime satellite imagery (250 terabytes) from DMSP and VIIRS sensors. Foundational dataset for using lights as GDP proxy.\nCategory: Geospatial\nTags: satellite, nighttime-lights, GDP, development, World Bank\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:336:predicting-poverty-replication-data", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: Predicting Poverty Replication Data\nDescription: Satellite imagery and survey data from Jean et al. (Science 2016) for predicting poverty in African countries using deep learning.\nCategory: Geospatial\nTags: satellite, poverty, deep-learning, Africa, development\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "dataset:337:lobster-limit-order-book-system", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching dataset metadata for tech-econ.org.\n\nDATASET:\nName: LOBSTER (Limit Order Book System)\nDescription: High-frequency limit order book tick data for NASDAQ stocks reconstructed from ITCH messages. Gold standard for market microstructure research.\nCategory: Financial Services\nTags: high-frequency, limit-order-book, NASDAQ, tick-data, market-microstructure\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"pandas-dataframes\", \"regression-analysis\", etc.],\n  \"topic_tags\": [\"e-commerce\", \"consumer-behavior\", \"pricing\", etc.],\n  \"summary\": \"2-3 sentences: What data is this? What can you do with it?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries to find this dataset\"],\n  \"use_cases\": [\"2-4 analysis scenarios\"],\n  \"domain_tags\": [\"retail\", \"healthcare\", \"fintech\", etc.],\n  \"data_modality\": \"tabular|text|image|time-series|graph|mixed\",\n  \"temporal_coverage\": \"Only if explicitly mentioned, else null\",\n  \"geographic_scope\": \"Only if explicitly mentioned, else null\",\n  \"size_category\": \"small|medium|large|massive - only if inferable, default medium\",\n  \"benchmark_usage\": [\"Common uses if mentioned in description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- DOMAIN_TAGS: Industry/sector tags based on description\n- SIZE_CATEGORY: Only specify if size is mentioned; otherwise use \"medium\"\n- TEMPORAL_COVERAGE: Only if years are explicitly mentioned\n- GEOGRAPHIC_SCOPE: Only if location/region is explicitly mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this DATASET, include:\n- Data structure and schema (rows, columns, variables)\n- Collection methodology and data sources\n- Coverage: temporal, geographic, demographic\n- Key variables and what they measure\n- Data quality and known limitations\n- Common preprocessing steps needed\n- Research questions it can address\n- Types of analyses it supports (regression, ML, descriptive)\n- How researchers typically use this in studies\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:0:scott-cunningham-causal-inference-substack", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Scott Cunningham: Causal Inference Substack\nDescription: Substack and podcast 'The Mixtape with Scott' featuring interviews with leading causal inference researchers. Bridges academic methods and practical application.\nCategory: Causal Inference\nType: Newsletter\nTags: Causal Inference & ML, Podcast, Newsletter\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:1:causal-inference-for-the-brave-and-true", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Inference for the Brave and True\nDescription: Matheus Facure's comprehensive Python-based coverage of synthetic control, difference-in-differences, and other causal methods central to marketing science.\nCategory: Causal Inference\nType: Book\nTags: Causal Inference & ML, Python, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:5:causal-inference-the-mixtape", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Inference: The Mixtape\nDescription: Scott Cunningham's academic-quality but accessible methodology covering causal methods essential for marketing measurement.\nCategory: Causal Inference\nType: Book\nTags: Causal Inference & ML, Economics, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:6:coding-for-economists-arthur-turrell", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Coding for Economists (Arthur Turrell)\nDescription: Python workflow for economists covering data transformation, econometrics, Bayesian inference, and ML. Modern Python-first approach.\nCategory: Causal Inference\nType: Book\nTags: Coding, Online Book, Python, Econometrics, Workflow\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:9:how-to-measure-cohort-retention-lenny-s-newsletter", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: How to Measure Cohort Retention (Lenny's Newsletter)\nDescription: The most comprehensive retention measurement guide. SQL implementations, bounded vs unbounded retention definitions, visualization best practices. When to use X-day vs unbounded retention.\nCategory: Bayesian Methods\nType: Tutorial\nTags: Product Analytics, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:11:seeing-theory-brown", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Seeing Theory (Brown)\nDescription: Beautiful interactive visualizations for building intuition\nCategory: Bayesian Methods\nType: Guide\nTags: Statistics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:12:how-superhuman-built-an-engine-to-find-pmf-first-round", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: How Superhuman Built an Engine to Find PMF (First Round)\nDescription: Operationalizes Sean Ellis's '40% very disappointed' survey into a systematic process. How Superhuman went from 22% to 58% PMF score using segmentation. Most referenced First Round article.\nCategory: Bayesian Methods\nType: Article\nTags: Product Analytics, Case Study\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:14:scipy-stats-documentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Scipy.stats Documentation\nDescription: Reference for distributions and tests\nCategory: Bayesian Methods\nType: Guide\nTags: Statistics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:15:evan-miller-how-not-to-run-an-a-b-test", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Evan Miller: How Not To Run an A/B Test\nDescription: The 250,000+ view article that shaped industry thinking on peeking problems. Essential reading on why continuously monitoring A/B tests leads to false positives.\nCategory: A/B Testing\nType: Blog\nTags: A/B Testing, Statistics, Peeking Problem\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:16:beyond-jupyter", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Beyond Jupyter\nDescription: Software design principles for ML applications. Go from messy notebooks to maintainable, modular code with OOP essentials and refactoring guides.\nCategory: Programming\nType: Tutorial\nTags: Coding, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:17:visualgo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: VisuAlgo\nDescription: Animated algorithm visualizations \u2014 sorting, graphs, DP\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:18:thealgorithms-python", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: TheAlgorithms/Python\nDescription: 200+ algorithm implementations in Python \u2014 reference code\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:19:postman-academy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Postman Academy\nDescription: Free API certification path \u2014 often more useful than scraping\nCategory: Programming\nType: Guide\nTags: Engineering\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:20:playwright-for-python", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Playwright for Python\nDescription: Modern browser automation (faster than Selenium)\nCategory: Programming\nType: Guide\nTags: Engineering\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:23:matteo-courthoud-s-experimentation-series", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Matteo Courthoud's Experimentation Series\nDescription: Connects experimentation to econometric foundations. Covers CUPED (linking to DiD), group sequential testing, Bayesian A/B testing, and clustered standard errors. Every post includes complete Python code.\nCategory: A/B Testing\nType: Blog\nTags: Causal Inference, Tutorial, Experimentation\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:24:the-missing-semester-mit", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: The Missing Semester (MIT)\nDescription: Command line, Git, debugging, shell scripting. The CS skills they don't teach in econ PhD programs but you absolutely need.\nCategory: Programming\nType: Course\nTags: Coding, Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:25:problem-solving-with-algorithms-data-structures-python", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Problem Solving with Algorithms & Data Structures (Python)\nDescription: Free interactive textbook \u2014 visualizations and runnable code\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:26:real-python-data-structures", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Real Python: Data Structures\nDescription: Practical guide with Python-specific implementations\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:27:leetcode-explore-data-structures", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LeetCode Explore: Data Structures\nDescription: Structured practice cards with solutions\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:28:usf-data-structure-visualizations", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: USF Data Structure Visualizations\nDescription: Interactive animations \u2014 see how trees, heaps, and graphs work\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:29:freecodecamp-algorithms-course", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: freeCodeCamp: Algorithms Course\nDescription: 8-hour free video course \u2014 clear explanations\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:30:abdul-bari-youtube", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Abdul Bari (YouTube)\nDescription: Exceptional whiteboard DSA explanations\nCategory: Programming\nType: Guide\nTags: Computer Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:35:automate-the-boring-stuff-with-python", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Automate the Boring Stuff with Python\nDescription: The best free Python book for non-programmers. Web scraping, Excel automation, file management \u2014 practical skills for data work.\nCategory: Programming\nType: Book\nTags: Automation, Online Book\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:36:scrapy-documentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Scrapy Documentation\nDescription: The industrial-strength web scraping framework for Python. Build spiders, handle anti-bot measures, and scale to millions of pages.\nCategory: Programming\nType: Guide\nTags: Automation, Docs\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:37:real-python-web-scraping", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Real Python: Web Scraping\nDescription: Practical guide to scraping with BeautifulSoup and requests. Parse HTML, handle pagination, and extract structured data.\nCategory: Programming\nType: Tutorial\nTags: Automation, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:38:python-for-econometrics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Python for Econometrics\nDescription: Kevin Sheppard's comprehensive intro for researchers. NumPy, pandas, statsmodels, and econometric applications.\nCategory: Programming\nType: Book\nTags: Coding, Online Book\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:39:sqlbolt", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: SQLBolt\nDescription: Learn SQL with interactive exercises. No setup required \u2014 run queries right in the browser. Perfect for beginners.\nCategory: Programming\nType: Course\nTags: SQL, Interactive Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:41:coding-for-practitioners", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Coding for practitioners\nDescription: Built specifically for econ researchers\nCategory: Programming\nType: Guide\nTags: Python Fundamentals\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:42:python-data-science-handbook", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Python Data Science Handbook\nDescription: Free reference for NumPy, Pandas, Matplotlib\nCategory: Programming\nType: Guide\nTags: Python Fundamentals\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:43:mode-sql-tutorial", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Mode SQL Tutorial\nDescription: Interactive SQL lessons from basic to advanced. Great for learning JOINs, window functions, and subqueries with a real database.\nCategory: Programming\nType: Tutorial\nTags: SQL, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:45:datalemur", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: DataLemur\nDescription: Real DS interview questions with business context\nCategory: Programming\nType: Guide\nTags: SQL & Databases\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:47:leetcode-sql-50", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LeetCode SQL 50\nDescription: 50 essential SQL problems to master for interviews. CTEs, window functions, and common patterns used at FAANG.\nCategory: Programming\nType: Tool\nTags: SQL, Practice Problems\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:48:duckdb-documentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: DuckDB Documentation\nDescription: Modern in-process SQL database. Runs on your laptop, reads Parquet directly, and is perfect for analytics. The new pandas killer.\nCategory: Programming\nType: Guide\nTags: SQL, Docs\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:49:neetcode", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: NeetCode\nDescription: Curated LeetCode roadmap organized by pattern. Video explanations that actually make sense. The modern way to prep for coding interviews.\nCategory: Programming\nType: Course\nTags: LeetCode, Course + Practice\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:50:blind-75", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Blind 75\nDescription: The 75 most important LeetCode problems. Arrays, strings, trees, graphs, DP \u2014 if you can solve these, you can handle any interview.\nCategory: Programming\nType: Tool\nTags: LeetCode, Problem Set\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:51:leetcode-patterns", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LeetCode Patterns\nDescription: 14 patterns to solve any coding interview question. Two pointers, sliding window, BFS/DFS, and more \u2014 with Python templates.\nCategory: Programming\nType: Guide\nTags: LeetCode, Study Guide\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:52:select-star-sql", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: SELECT Star SQL\nDescription: Interactive book teaching SQL through meaningful analysis\nCategory: Programming\nType: Guide\nTags: SQL & Databases\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:53:8-week-sql-challenge-danny-ma", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: 8 Week SQL Challenge (Danny Ma)\nDescription: 8 business case studies with CTEs and window functions\nCategory: Programming\nType: Guide\nTags: SQL & Databases\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:56:mark-white-s-practical-causal-forest-tutorial", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Mark White's Practical Causal Forest Tutorial\nDescription: Explains why optimize directly on causal effects, not outcomes. Complete workflow from data prep to interpretation using GRF package. Written for applied researchers transitioning to causal ML.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Inference, Causal ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:60:evan-miller-s-a-b-testing-tools", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Evan Miller's A/B Testing Tools\nDescription: Interactive calculators for sample size, chi-squared, sequential sampling, and t-tests. The companion article 'How Not To Run an A/B Test' is the canonical reference on why repeated significance testing inflates false positives.\nCategory: A/B Testing\nType: Tool\nTags: Experimentation, Tools\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:61:netflix-tech-blog-what-is-an-a-b-test", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix Tech Blog: What is an A/B Test?\nDescription: Multi-part series covering metric selection, sequential testing at scale, quasi-experimentation when SUTVA is violated, and interleaving for recommendation testing. Published at KDD.\nCategory: A/B Testing\nType: Blog\nTags: Experimentation, Blog\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:62:linkedin-our-evolution-towards-t-rex", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LinkedIn: Our Evolution Towards T-REX\nDescription: Scaling to 41,000 simultaneous A/B tests on 700M+ members. How LinkedIn built infrastructure to support massive-scale experimentation.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Platform, Scale\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:65:matteo-courthoud-s-meta-learners-tutorial", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Matteo Courthoud's Meta-Learners Tutorial\nDescription: S-learner, T-learner, X-learner with detailed math, causal trees/forests, AIPW estimators. Uses Uber's CausalML package for demos. Complete Jupyter notebooks on GitHub.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Inference, Causal ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:66:kdd-2021-tutorial-causal-inference-with-econml-and-causalml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: KDD 2021 Tutorial: Causal Inference with EconML and CausalML\nDescription: Industry workshop with 4 case studies from Uber, TripAdvisor, Microsoft. Ready-to-run Google Colab notebooks covering uplift modeling, customer segmentation, and long-term ROI estimation.\nCategory: Causal Inference\nType: Course\nTags: Causal Inference, Causal ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:67:double-debiased-machine-learning-guide", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Double/Debiased Machine Learning Guide\nDescription: From the original DML authors. Explains Neyman orthogonality, cross-fitting, DML with text/complex data. Focuses on practical implementation rather than theory.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Inference, Causal ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:72:teconomics-machine-learning-meets-instrumental-variables", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Teconomics: Machine Learning Meets Instrumental Variables\nDescription: How to reframe past A/B tests as instruments for behaviors you cannot randomize. Covers IV for behavioral effects, Deep IV, and ML for instrument selection. Actionable for data scientists.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, IV, Instrumental Variables, Machine Learning\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:73:uber-engineering-uplift-modeling-for-multiple-treatments", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Uber Engineering: Uplift Modeling for Multiple Treatments\nDescription: Extending X-Learner and R-Learner to multiple treatments with cost optimization. Production system design for uplift models at scale with cost-aware treatment allocation.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, Causal ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:74:brady-neal-s-introduction-to-causal-inference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Brady Neal's Introduction to Causal Inference\nDescription: 14-week video course covering potential outcomes, DAGs, do-calculus, and causal discovery. Features guest lectures from Susan Athey, Alberto Abadie, and Yoshua Bengio. Bridges ML and econometric traditions.\nCategory: Machine Learning\nType: Course\nTags: Causal Inference, Video Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:75:stanford-ml-causal-inference-short-course", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Stanford ML & Causal Inference Short Course\nDescription: Video lectures from Susan Athey, Jann Spiess, and Stefan Wager covering ML vs. econometrics, ATEs with propensity scores, CATE estimation with causal forests, and loss functions for causal inference.\nCategory: Machine Learning\nType: Course\nTags: Causal Inference, Video Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:76:andrew-heiss-s-dag-and-backdoor-tutorials", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Andrew Heiss's DAG and Backdoor Tutorials\nDescription: Hands-on tutorials on building DAGs with ggdag, backdoor criterion, confounders/colliders, d-separation, and propensity scores. Uses real variable names with complete R code.\nCategory: Machine Learning\nType: Tutorial\nTags: Causal Inference, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:81:r-causal-book-dag-construction-chapter", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: R-causal Book: DAG Construction Chapter\nDescription: DAG construction with ggdag. Practical guide to building directed acyclic graphs for causal inference in R.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Inference, DAGs, R\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:85:dirk-bergemann-s-yale-courses", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Dirk Bergemann's Yale Courses\nDescription: Yale courses on information economics, mechanism design, and dynamic auctions from leading auction theory researcher\nCategory: Machine Learning\nType: Course\nTags: Yale, mechanism design, information economics, auctions\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:90:quantecon-datascience", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: QuantEcon DataScience\nDescription: Economic modeling with data science from UBC Vancouver. Python-based applications in economics with real student project examples.\nCategory: Causal Inference\nType: Course\nTags: Python, Economics, Data Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:103:lost-statistics-causal-forest-tutorial", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LOST Statistics: Causal Forest Tutorial\nDescription: Practical guide to implementing causal forests for heterogeneous treatment effect estimation with code examples in R and Python.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Forest, GRF, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:115:microsoft-research-end-to-end-causal-inference-at-scale-demo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Microsoft Research: End-to-End Causal Inference at Scale Demo\nDescription: Demo video showcasing Microsoft's EconML ecosystem for production causal inference, from data prep to deployment.\nCategory: Causal Inference\nType: Video\nTags: EconML, Causal Inference, Production\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:116:causal-econometrics-course", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Econometrics Course\nDescription: Graduate-level credibility revolution methods. Comprehensive coverage of modern causal inference techniques for econometricians.\nCategory: Causal Inference\nType: Course\nTags: Econometrics, Causal Inference, Graduate\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:117:adam-kelleher-causality-python-package", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Adam Kelleher: Causality Python Package\nDescription: Python implementation of causal inference algorithms including do-sampler, causal graph inference, and conditional independence testing.\nCategory: Causal Inference\nType: Tool\nTags: Python, Causal Inference, DoWhy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:118:awesome-causal-inference-matteo-courthoud", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Awesome Causal Inference (Matteo Courthoud)\nDescription: Comprehensive GitHub repository curating causal inference resources. Papers, packages, tutorials, and datasets organized by topic.\nCategory: Causal Inference\nType: Guide\nTags: Curated List, Causal Inference, GitHub\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:120:doordash-leveraging-causal-inference-for-forecasts", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: DoorDash: Leveraging Causal Inference for Forecasts\nDescription: How DoorDash combines causal inference with forecasting to understand intervention impacts and improve demand prediction accuracy.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, Forecasting, DoorDash\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:121:applied-causal-inference-book-chernozhukov-et-al", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Applied Causal Inference Book (Chernozhukov et al.)\nDescription: Comprehensive online textbook covering DML, causal forests, and modern causal ML methods with Python/R code. Essential reference for practitioners.\nCategory: Causal Inference\nType: Book\nTags: Causal Inference, Machine Learning, Textbook\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:122:causal-wizard-reading-list", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Wizard Reading List\nDescription: Organized learning path for causal inference. Quality-assessed progression from basics to advanced methods.\nCategory: Causal Inference\nType: Guide\nTags: Reading List, Causal Inference, Learning Path\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:146:uber-engineering-causal-inference-at-uber", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Uber Engineering: Causal Inference at Uber\nDescription: Real industry application showing how PhD-level methods translate to business problems. Covers propensity score matching at scale, RDD for dynamic pricing, and mediation modeling.\nCategory: Machine Learning\nType: Blog\nTags: Causal Inference, Blog\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:155:csis-strategic-technologies-program", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: CSIS Strategic Technologies Program\nDescription: Research and events on defense technology, cybersecurity, and emerging technologies from the #1 ranked defense think tank\nCategory: Computational Economics\nType: Tool\nTags: CSIS, technology, cybersecurity, policy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:156:netflix-return-aware-experimentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Return-Aware Experimentation\nDescription: KDD 2025 Best Paper on optimal experiment design with limited resources. Framework for designing experiments that maximize learning given resource constraints.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Experiment Design\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:157:dario-sansone-ml-for-economists-resources", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Dario Sansone: ML for Economists Resources\nDescription: Curated list of ML and causal inference resources for economists. Papers, tools, and comprehensive meta-resource collection.\nCategory: Causal Inference\nType: Guide\nTags: Machine Learning, Economics, Curated List\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:159:pywhy-causal-discovery-example", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: PyWhy: Causal Discovery Example\nDescription: PC, GES, LiNGAM algorithms for discovering causal structure from data. When you need to discover the causal graph rather than assume it.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Inference, Causal Discovery, Python\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:160:google-research-causalimpact-paper", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Google Research: CausalImpact Paper\nDescription: Foundation paper for CausalImpact package: inferring causal impact using Bayesian structural time-series models for interrupted time series.\nCategory: Causal Inference\nType: Article\nTags: CausalImpact, Time Series, Google\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:161:shubhanshu-mishra-awesome-causality", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Shubhanshu Mishra: Awesome Causality\nDescription: Extensive collection of causality resources including datasets, books, courses, videos, and code implementations.\nCategory: Causal Inference\nType: Guide\nTags: Curated List, Causality, Datasets\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:164:evan-miller-formulas-for-bayesian-a-b-testing", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Evan Miller: Formulas for Bayesian A/B Testing\nDescription: Mathematical foundations for Bayesian approaches to A/B testing. Derivations of exact formulas for posterior probabilities and expected loss.\nCategory: A/B Testing\nType: Blog\nTags: Bayesian, A/B Testing, Statistics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:165:doordash-using-back-door-adjustment-for-pre-post-analysis", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: DoorDash: Using Back-Door Adjustment for Pre-Post Analysis\nDescription: Causal graphs and covariate adjustment for pre-post analysis. How to properly control for confounders when randomization isn't possible.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, DAGs, Observational\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:166:spotify-new-experimentation-platform-part-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Spotify: New Experimentation Platform (Part 1)\nDescription: Journey from ABBA to EP; Metrics Catalog for self-service analysis. Evolution of Spotify's experimentation infrastructure and lessons learned.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Platform\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:167:ben-elsner-causal-inference-policy-evaluation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Ben Elsner: Causal Inference & Policy Evaluation\nDescription: European policy evaluation focus on causal inference methods. Practical approach to evaluating interventions.\nCategory: Causal Inference\nType: Course\nTags: Policy Evaluation, Causal Inference, Europe\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:168:uber-making-experiment-evaluation-engine-100x-faster", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Uber: Making Experiment Evaluation Engine 100x Faster\nDescription: Engineering deep-dive on scaling experimentation infrastructure to 10M+ evaluations per second. Covers optimization techniques for high-throughput experiment analysis.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Infrastructure\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:169:statquest-with-josh-starmer", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: StatQuest with Josh Starmer\nDescription: Visual explanations of cross-validation, regularization, gradient boosting, PCA, and bias-variance tradeoff. 675,000+ subscribers. Fills conceptual gaps that course-based learning misses.\nCategory: Bayesian Methods\nType: Video\nTags: Statistics, Machine Learning, Video\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:170:netflix-it-s-all-a-bout-testing-the-experimentation-platform", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: It's All A/Bout Testing - The Experimentation Platform\nDescription: Foundational overview of Netflix experimentation covering allocation, Ignite analysis tool, and monitoring. Architecture of one of the most sophisticated A/B testing platforms.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Platform\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:171:growthbook-s-experimentation-fundamentals", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: GrowthBook's Experimentation Fundamentals\nDescription: Complete single-page reference covering hypothesis formation, statistical significance, Type I/II errors, MDE, power analysis, A/A tests, novelty effects, and experiment interactions. Notes that industry success rates are only ~33%.\nCategory: A/B Testing\nType: Tutorial\nTags: Experimentation, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:176:meta-instagram-notification-management-with-ml-and-causal-inference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Meta: Instagram Notification Management with ML and Causal Inference\nDescription: How Instagram uses ML and causal methods to optimize notification delivery, balancing engagement with user experience.\nCategory: Causal Inference\nType: Blog\nTags: Machine Learning, Causal Inference, Instagram\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:177:the-effect-nick-huntington-klein", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: The Effect (Nick Huntington-Klein)\nDescription: Free online textbook on research design and causal inference. 60+ video lectures with code in R, Stata, and Python. The replacement for Mastering Metrics.\nCategory: Causal Inference\nType: Book\nTags: Causal Inference, Textbook, Free\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:179:yanir-seroussi-curated-causal-inference-resources", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Yanir Seroussi: Curated Causal Inference Resources\nDescription: Comprehensive collection of causal inference learning resources. Curated list covering books, courses, software, and papers for practitioners.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, Learning Resources\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:180:doordash-causal-modeling-to-get-value-from-flat-experiment-results", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: DoorDash: Causal Modeling to Get Value from Flat Experiment Results\nDescription: Extracting value from neutral experiments via CATE estimation using S-learner and T-learner. When overall effects are null, heterogeneous effects may still exist.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, HTE, Meta-learners\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:181:data-analysis-journal-olga-berezovsky", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Data Analysis Journal (Olga Berezovsky)\nDescription: Weekly newsletter bridging academic statistics and product analytics practice. Experimentation guides, A/B test checklists, and workflow best practices.\nCategory: A/B Testing\nType: Newsletter\nTags: Product Analytics, A/B Testing, Data Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:182:nick-huntington-klein-animated-causal-graphs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Nick Huntington-Klein: Animated Causal Graphs\nDescription: Innovative visual demonstrations of how different causal methods work. Animated DAGs showing confounding, selection bias, and identification strategies.\nCategory: Causal Inference\nType: Tool\nTags: DAGs, Visualization, Pedagogy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:183:stanford-fintech-sendhil-mullainathan-on-ml-as-tool-for-science", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Stanford Fintech: Sendhil Mullainathan on ML as Tool for Science\nDescription: ABFR webinar where Mullainathan discusses ML's role in scientific discovery, moving beyond prediction to understanding causal mechanisms.\nCategory: Causal Inference\nType: Video\nTags: Machine Learning, Science, Methodology\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:186:adam-kelleher-causal-data-science-medium-series", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Adam Kelleher: Causal Data Science Medium Series\nDescription: Former BuzzFeed data scientist's accessible series on graphical causal inference. 'If Correlation Doesn't Imply Causation, Then What Does?' and more.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, DAGs, Pearl\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:189:rand-research-archive", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: RAND Research Archive\nDescription: Free access to decades of defense policy research from the nation's oldest think tank, founded in 1948\nCategory: Computational Economics\nType: Tool\nTags: RAND, research, defense policy, think tank\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:191:egap-learning-days-field-experiments", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: EGAP Learning Days: Field Experiments\nDescription: Theory and practice of field experiments with international development focus. Randomization, power analysis, and ethical considerations.\nCategory: Causal Inference\nType: Course\nTags: Field Experiments, RCT, Development\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:193:meta-how-meta-tests-products-with-strong-network-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Meta: How Meta Tests Products with Strong Network Effects\nDescription: Cluster experiments, power vs purity tradeoffs. How Facebook handles experimentation when treatment effects spill over between users.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Network Effects, Cluster Randomization\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:194:spotify-confidence", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Spotify Confidence\nDescription: Spotify's experimentation platform for feature flagging and A/B testing. SDK for controlled rollouts with built-in statistical analysis.\nCategory: A/B Testing\nType: Tool\nTags: Feature Flags, A/B Testing, Experimentation Platform, Spotify\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:196:airbnb-ace-artificial-counterfactual-estimation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Airbnb: ACE - Artificial Counterfactual Estimation\nDescription: Machine learning-based causal inference at Airbnb. Using ML to estimate counterfactuals when traditional experimental methods aren't feasible.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, Machine Learning, Counterfactuals\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:197:clearcode-adtech-book", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Clearcode AdTech Book\nDescription: Free online guide to programmatic advertising ecosystem with continuously updated technical coverage\nCategory: Frameworks & Strategy\nType: Guide\nTags: programmatic, ad tech, guide, free\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:199:stanford-stats-361-causal-inference-lecture-notes-wager", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Stanford STATS 361: Causal Inference Lecture Notes (Wager)\nDescription: Stefan Wager's graduate course notes on causal inference with machine learning: heterogeneous treatment effects, conformal inference, and forest methods.\nCategory: Causal Inference\nType: Course\nTags: Causal Inference, Statistics, Stanford\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:201:airbnb-experiments-at-airbnb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Airbnb: Experiments at Airbnb\nDescription: Foundation article on Airbnb's experimentation platform: A/B testing infrastructure, metric design, and lessons from running experiments at scale.\nCategory: A/B Testing\nType: Blog\nTags: Experimentation, A/B Testing, Airbnb\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:202:apoorva-lal-applied-econometrics-notes", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Apoorva Lal: Applied Econometrics Notes\nDescription: Condensed notes with working code on Angrist & Pischke methods. Practical implementations of Mostly Harmless Econometrics.\nCategory: Causal Inference\nType: Article\nTags: Econometrics, Code, Angrist\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:203:imf-cross-validation-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: IMF: Cross-Validation for Economists\nDescription: IMF training material on applying cross-validation techniques in economic research, bridging ML best practices with econometric applications.\nCategory: Causal Inference\nType: Tutorial\nTags: Cross-Validation, Machine Learning, IMF\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:206:lukas-vermeer-building-experimentation-infrastructure", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Lukas Vermeer: Building Experimentation Infrastructure\nDescription: Booking.com's Director of Experimentation on building culture and infrastructure for 1000+ concurrent experiments.\nCategory: A/B Testing\nType: Blog\nTags: Experimentation, Booking.com, Infrastructure\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:208:lyft-challenges-in-experimentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Lyft: Challenges in Experimentation\nDescription: Region-split tests with synthetic control and residualization for variance reduction. Advanced techniques for experimentation in ridesharing marketplaces.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Synthetic Control, Variance Reduction\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:210:uchicago-law-discrimination-by-algorithm-and-people", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: UChicago Law: Discrimination by Algorithm and People\nDescription: Sendhil Mullainathan examines algorithmic discrimination, comparing ML-based decisions to human decisions, with policy implications.\nCategory: Causal Inference\nType: Video\nTags: Algorithmic Fairness, Discrimination, Policy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:211:netflix-computational-causal-inference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Computational Causal Inference\nDescription: Technical deep-dive into Netflix's causal inference infrastructure, software tools, and scalable computation approaches for causal analysis.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, Infrastructure, Netflix\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:213:world-of-daas-susan-athey-tech-economists-and-ml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: World of DaaS: Susan Athey - Tech Economists and ML\nDescription: SafeGraph podcast featuring Susan Athey on the role of tech economists, machine learning applications in economics, and causation in industry settings.\nCategory: Causal Inference\nType: Podcast\nTags: Tech Economics, Machine Learning, Industry\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:217:ronny-kohavi-trustworthy-online-controlled-experiments", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Ronny Kohavi: Trustworthy Online Controlled Experiments\nDescription: The definitive book on A/B testing methodology by the architect of experimentation at Microsoft, Amazon, and Airbnb. 27,000+ citations.\nCategory: A/B Testing\nType: Book\nTags: A/B Testing, Experimentation, Ronny Kohavi\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:220:georgetown-ma-in-security-studies", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Georgetown MA in Security Studies\nDescription: Premier graduate program with Economics & Security requirement, training the next generation of defense analysts\nCategory: Machine Learning\nType: Course\nTags: Georgetown, security studies, economics, graduate\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:221:microsoft-exp-deep-dive-into-variance-reduction", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Microsoft ExP: Deep Dive into Variance Reduction\nDescription: From the team that invented CUPED. Comprehensive guide to variance reduction techniques for online experiments from Microsoft's Experimentation Platform.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, CUPED, Variance Reduction\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:224:netflix-decision-making-at-netflix", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Decision Making at Netflix\nDescription: Scientific method for pricing decisions at 150M+ subscriber scale. How Netflix approaches experimentation for subscription pricing and content decisions.\nCategory: A/B Testing\nType: Article\nTags: Experimentation, Decision Making, Subscription\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:225:econtalk-susan-athey-on-ml-big-data-and-causation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: EconTalk: Susan Athey on ML, Big Data, and Causation\nDescription: Susan Athey discusses how machine learning transforms economic research, the importance of big data for causal inference, and bridging CS/economics methodologies.\nCategory: Causal Inference\nType: Podcast\nTags: Machine Learning, Causal Inference, Big Data\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:226:uber-analyzing-experiment-outcomes-beyond-average-treatment-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Uber: Analyzing Experiment Outcomes Beyond Average Treatment Effects\nDescription: Quantile treatment effects for understanding distributional differences in marketplaces. Goes beyond ATE to measure how treatments affect different parts of the outcome distribution.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Heterogeneous Effects\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:230:netflix-a-survey-of-causal-inference-applications", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: A Survey of Causal Inference Applications\nDescription: Comprehensive overview of how Netflix applies causal inference across experimentation, personalization, and content decisions at scale.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, Netflix, Applications\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:233:exp-platform-microsoft-experimentation-resources", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: ExP Platform: Microsoft Experimentation Resources\nDescription: Comprehensive experimentation platform guide from Microsoft's exp-platform team. Includes CUPED variance reduction, SRM detection, and metric design.\nCategory: A/B Testing\nType: Guide\nTags: Experimentation, CUPED, Microsoft\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:238:google-machine-learning-crash-course", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Google Machine Learning Crash Course\nDescription: 15-hour interactive course originally for Google engineers, refreshed 2024 with LLMs/AutoML. Covers supervised learning, feature engineering, and production ML with Colab exercises. Teaches exact mental models Google engineers use.\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:242:interpretable-machine-learning-book-christoph-molnar", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Interpretable Machine Learning Book (Christoph Molnar)\nDescription: The definitive online book on ML interpretability: SHAP, LIME, PDP, feature importance. Essential for understanding black-box model predictions.\nCategory: Causal Inference\nType: Book\nTags: Interpretability, Machine Learning, SHAP\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:245:lost-stats-event-study-designs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LOST Stats: Event Study Designs\nDescription: Sun & Abraham estimator with code. Practical implementation of modern event study designs addressing staggered treatment timing issues.\nCategory: Causal Inference\nType: Tutorial\nTags: Causal Inference, DiD, Event Study\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:253:spotify-risk-aware-product-decisions-in-a-b-tests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Spotify: Risk-Aware Product Decisions in A/B Tests\nDescription: Framework for combining success, guardrail, deterioration, and quality metrics. How to make decisions when multiple metrics move in different directions.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Metrics, Decision Making\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:255:spotify-encouragement-designs-and-instrumental-variables-for-a-b-testing", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Spotify: Encouragement Designs and Instrumental Variables for A/B Testing\nDescription: IV estimation for experiments with noncompliance. How to handle experiments where users don't follow their assigned treatment, using complier populations.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, Instrumental Variables, Noncompliance\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:259:linkedin-detecting-interference-an-a-b-test-of-a-b-tests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LinkedIn: Detecting Interference - An A/B Test of A/B Tests\nDescription: Using cluster randomization to detect when user-level randomization causes interference. Methodology to test whether your experiments have network effects.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Network Effects, Interference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:263:microsoft-research-adversarial-ml-and-instrumental-variables", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Microsoft Research: Adversarial ML and Instrumental Variables\nDescription: Innovative approach combining adversarial machine learning with instrumental variables for flexible causal modeling in complex settings.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, Instrumental Variables, ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:267:made-with-ml", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Made With ML\nDescription: Implementation-first approach: build models from scratch with NumPy before PyTorch. Emphasizes clean, production-quality code with proper software engineering practices. By Goku Mohandas (ex-Apple ML).\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:270:susan-athey-s-stanford-gsb-courses", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Susan Athey's Stanford GSB Courses\nDescription: Stanford courses on digital economics, machine learning for causal inference, and tech platform economics from former Microsoft Chief Economist\nCategory: Machine Learning\nType: Course\nTags: Stanford, digital economics, causal inference, platforms\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:271:knowledge-project-102-sendhil-mullainathan", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Knowledge Project #102: Sendhil Mullainathan\nDescription: Deep conversation with Sendhil Mullainathan on behavioral economics, machine learning in social science, and decision-making under uncertainty.\nCategory: Causal Inference\nType: Podcast\nTags: Behavioral Economics, Machine Learning, Decision Making\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:272:ronny-kohavi-seven-rules-of-thumb-for-web-site-experimenters", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Ronny Kohavi: Seven Rules of Thumb for Web Site Experimenters\nDescription: Foundational paper establishing core practices for online experimentation. Rules still followed at major tech companies today.\nCategory: A/B Testing\nType: Article\nTags: Experimentation, Best Practices, Kohavi\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:273:defense-acquisition-university-dau", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Defense Acquisition University (DAU)\nDescription: Official DoD training for acquisition professionals covering contracting, program management, and cost estimation\nCategory: Machine Learning\nType: Course\nTags: DoD, acquisition, contracting, certification\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:274:linkedin-a-b-testing-variant-assignment-at-scale", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LinkedIn: A/B Testing Variant Assignment at Scale\nDescription: Hash-based variant assignment for trillions of daily invocations. Technical deep-dive on deterministic, consistent randomization at LinkedIn scale.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Randomization, Infrastructure\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:281:mit-ocw-energy-decisions-markets-and-policies", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: MIT OCW: Energy Decisions, Markets, and Policies\nDescription: MIT graduate course on energy economics covering market design, regulation, and policy analysis\nCategory: Machine Learning\nType: Course\nTags: MIT, energy economics, market design, regulation\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:294:andrew-ng-s-machine-learning-specialization", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Andrew Ng's Machine Learning Specialization\nDescription: Comprehensive theoretical grounding redesigned 2022 with modern Python. Three-course sequence on supervised/unsupervised learning and recommender systems. 4.9/5 from 37,000+ reviews. Free to audit.\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, Course\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:297:mit-ocw-engineering-economics-and-regulation-of-the-electric-power-sector", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: MIT OCW: Engineering, Economics, and Regulation of the Electric Power Sector\nDescription: MIT course bridging power systems engineering with electricity market economics and regulatory policy\nCategory: Machine Learning\nType: Course\nTags: MIT, power systems, regulation, engineering economics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:298:netflix-round-2-causal-inference-survey-synthetic-control", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Round 2 - Causal Inference Survey (Synthetic Control)\nDescription: Follow-up survey focusing on synthetic control methods, panel data approaches, and advanced causal techniques used at Netflix.\nCategory: Causal Inference\nType: Blog\nTags: Synthetic Control, Causal Inference, Netflix\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:301:hal-varian-big-data-new-tricks-for-econometrics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Hal Varian: Big Data - New Tricks for Econometrics\nDescription: Seminal 2013 paper on ML methods relevant for economists: classification/regression trees, random forests, LASSO, and cross-validation techniques.\nCategory: Causal Inference\nType: Article\nTags: Machine Learning, Econometrics, Methods\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:314:capitalisn-t-sendhil-mullainathan-on-who-controls-ai", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Capitalisn't: Sendhil Mullainathan on Who Controls AI\nDescription: Chicago Booth podcast exploring AI governance, algorithmic decision-making, and the economic implications of who shapes AI development.\nCategory: Causal Inference\nType: Podcast\nTags: AI Governance, Economics, Policy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:324:hal-varian-machine-learning-and-econometrics-berkeley", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Hal Varian: Machine Learning and Econometrics (Berkeley)\nDescription: Google's Chief Economist on bridging ML and econometrics, covering prediction vs inference, variable selection, and modern statistical approaches.\nCategory: Causal Inference\nType: Video\nTags: Machine Learning, Econometrics, Google\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:327:dean-eckles-blog-on-network-experiments-and-social-influence", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Dean Eckles: Blog on Network Experiments and Social Influence\nDescription: MIT professor and former Facebook data scientist. Deep expertise in network experiments, social influence, and randomization at Facebook scale.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, Network Effects, Social Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:343:iab-and-iab-tech-lab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: IAB and IAB Tech Lab\nDescription: Industry standards body maintaining OpenRTB, ads.txt, sellers.json, VAST, and other programmatic advertising standards\nCategory: Operations Research\nType: Tool\nTags: standards, OpenRTB, ads.txt, programmatic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:348:linkedin-building-inclusive-products-through-a-b-testing", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: LinkedIn: Building Inclusive Products Through A/B Testing\nDescription: Novel approach to measuring inequality impact of experiments. How to ensure product changes don't disproportionately harm certain user groups.\nCategory: A/B Testing\nType: Article\nTags: AB Testing, Fairness, Inclusive Design\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:355:netflix-sequential-a-b-testing-keeps-the-world-streaming", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Sequential A/B Testing Keeps the World Streaming\nDescription: Two-part series on anytime-valid inference and sequential testing for Netflix canary deployments.\nCategory: A/B Testing\nType: Blog\nTags: Sequential Testing, A/B Testing, Anytime-Valid, Netflix\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:367:netflix-heterogeneous-treatment-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Heterogeneous Treatment Effects\nDescription: OCI platform for HTE estimation with doubly robust scoring and scalable policy learning. How Netflix identifies which users respond differently to treatments.\nCategory: Causal Inference\nType: Article\nTags: Causal Inference, HTE, Policy Learning\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:374:aea-afa-2019-impact-of-machine-learning-on-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: AEA/AFA 2019: Impact of Machine Learning on Economics\nDescription: Susan Athey's joint luncheon address on how ML is reshaping economic research, prediction policy problems, and heterogeneous treatment effects.\nCategory: Causal Inference\nType: Video\nTags: Machine Learning, Economics Research, Policy\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:394:energy-institute-at-haas-blog", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Energy Institute at Haas Blog\nDescription: UC Berkeley's Energy Institute blog featuring accessible research summaries on electricity markets, climate policy, and transportation. Written by leading energy economists.\nCategory: Energy & Utilities Economics\nType: Blog\nTags: Energy, Research, Berkeley, Accessible\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:395:energy-institute-at-haas-blog", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Energy Institute at Haas Blog\nDescription: Berkeley research blog covering energy economics, climate policy, and electricity markets with accessible analysis\nCategory: Frameworks & Strategy\nType: Blog\nTags: Berkeley, energy economics, climate, policy analysis\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:416:sipri-databases-and-research", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: SIPRI Databases and Research\nDescription: Independent research on armaments and arms control with authoritative databases and the annual SIPRI Yearbook\nCategory: Computational Economics\nType: Tool\nTags: SIPRI, arms control, military spending, research\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:447:media-rating-council-mrc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Media Rating Council (MRC)\nDescription: Industry body setting viewability standards and measurement accreditation for digital advertising\nCategory: Operations Research\nType: Tool\nTags: viewability, measurement, accreditation, standards\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:450:stanford-gsb-machine-learning-causal-inference-short-course", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Stanford GSB: Machine Learning & Causal Inference Short Course\nDescription: Free video course from Susan Athey, Jann Spiess, and Stefan Wager covering causal forests, double ML, and modern causal inference methods with R tutorials.\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, Causal Inference, R, Stanford\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:451:aea-continuing-education-ml-and-econometrics-2018", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: AEA Continuing Education: ML and Econometrics (2018)\nDescription: 9-part webcast series from Susan Athey and Guido Imbens on machine learning for economists. Freely available from the American Economic Association.\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, Econometrics, AEA, Webcast\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:452:machine-learning-for-economists-hebrew-university", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Machine Learning for Economists (Hebrew University)\nDescription: Complete course materials from Itamar Caspi and Ariel Mansura with R and Python tutorials on ML methods for economic research.\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, R, Python, Economics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:453:quantecon-ml-in-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: QuantEcon: ML in Economics\nDescription: Interactive Python tutorials on machine learning for prediction and causal inference from the QuantEcon project.\nCategory: Machine Learning\nType: Tutorial\nTags: Machine Learning, Python, Economics, Interactive\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:454:nlp-for-economists-mgse", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: NLP for Economists (MGSE)\nDescription: Munich Graduate School of Economics course on natural language processing methods for economics research by Sowmya Vajjala.\nCategory: Machine Learning\nType: Course\nTags: NLP, Text Analysis, Economics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:455:dair-ai-prompt-engineering-guide", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: DAIR.AI Prompt Engineering Guide\nDescription: Industry-standard open-source guide covering all prompting techniques for LLMs. Supports 13 languages with comprehensive coverage of chain-of-thought, few-shot, and advanced prompting methods.\nCategory: Machine Learning\nType: Tutorial\nTags: LLM, Prompt Engineering, AI\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:456:anthropic-prompt-engineering-documentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Anthropic Prompt Engineering Documentation\nDescription: Systematic approach to prompting Claude models effectively. Official documentation with best practices and examples.\nCategory: Machine Learning\nType: Tutorial\nTags: LLM, Claude, Prompt Engineering\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:457:econdl-deep-learning-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: EconDL: Deep Learning for Economists\nDescription: Companion website for Melissa Dell's JEL paper with demo notebooks, code examples, and tutorials on applying deep learning to economics research.\nCategory: Machine Learning\nType: Tutorial\nTags: Deep Learning, Economics, Notebooks\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:458:causal-inference-a-statistical-learning-approach", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Inference: A Statistical Learning Approach\nDescription: Stefan Wager's free PDF textbook covering causal inference from a machine learning perspective with theoretical foundations and practical applications.\nCategory: Causal Inference\nType: Book\nTags: Causal Inference, Machine Learning, Textbook, Free\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:459:applied-causal-inference-powered-by-ml-and-ai", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Applied Causal Inference Powered by ML and AI\nDescription: Chernozhukov et al. comprehensive textbook covering modern causal ML methods including double ML, causal forests, and policy learning.\nCategory: Causal Inference\nType: Book\nTags: Causal Inference, Machine Learning, Textbook\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:460:genai-for-econ-substack", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: GenAI for Econ Substack\nDescription: Anton Korinek's Substack newsletter with updates on LLM capabilities for economists and practical applications in research.\nCategory: Machine Learning\nType: Newsletter\nTags: LLM, AI, Economics, Newsletter\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:461:anton-korinek-research", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Anton Korinek Research\nDescription: Korinek's research page with all papers, updates, and resources on AI and economics including the evolving JEL paper series.\nCategory: Machine Learning\nType: Blog\nTags: AI, Economics, Research\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:462:coding-for-economists-nlp-chapter", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Coding for Economists: NLP Chapter\nDescription: Arthur Turrell's comprehensive guide covering text-as-data methods, topic modeling, and NLP applications for economists.\nCategory: Machine Learning\nType: Tutorial\nTags: NLP, Python, Economics, Text Analysis\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:463:dario-sansone-s-ml-resources-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Dario Sansone's ML Resources for Economists\nDescription: Curated collection of machine learning resources specifically for economists including papers, code, and tutorials.\nCategory: Machine Learning\nType: Blog\nTags: Machine Learning, Economics, Resources\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:464:imf-machine-learning-for-economists-course", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: IMF Machine Learning for Economists Course\nDescription: Course materials from Michal Andrle's IMF course on practical ML applications in economics and central banking.\nCategory: Machine Learning\nType: Course\nTags: Machine Learning, IMF, Central Banking\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:465:introduction-to-agent-based-modeling", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Introduction to Agent-Based Modeling\nDescription: Bill Rand's comprehensive free course on agent-based modeling from Santa Fe Institute's Complexity Explorer. Covers NetLogo, model design, and analysis.\nCategory: Computational Economics\nType: Course\nTags: Agent-Based Modeling, NetLogo, Complexity, Santa Fe Institute\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:466:agent-based-models-with-python-an-introduction-to-mesa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Agent-Based Models with Python: An Introduction to Mesa\nDescription: 21-lesson course on Complexity Explorer covering agent-based modeling in Python using Mesa framework. Builds Sugarscape and other classic models.\nCategory: Computational Economics\nType: Course\nTags: Mesa, Python, Agent-Based Modeling, Sugarscape\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:467:quantecon-python-lectures", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: QuantEcon Python Lectures\nDescription: Comprehensive lecture series on computational economics covering dynamic programming, rational expectations, Markov chains, and heterogeneous agents.\nCategory: Computational Economics\nType: Book\nTags: Python, Macroeconomics, Dynamic Programming, Quantitative Economics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:468:econ-ark-demark-examples", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Econ-ARK DemARK Examples\nDescription: Demonstration notebooks for HARK heterogeneous agent models. Includes buffer-stock, lifecycle, and Aiyagari model implementations.\nCategory: Computational Economics\nType: Tutorial\nTags: HARK, Heterogeneous Agents, Macroeconomics, Jupyter\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:469:sdv-getting-started-guide", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: SDV Getting Started Guide\nDescription: Official Synthetic Data Vault documentation covering GaussianCopula, CTGAN, and TVAE models for tabular data synthesis.\nCategory: Machine Learning\nType: Tutorial\nTags: Synthetic Data, SDV, Privacy, Machine Learning\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:470:andrew-heiss-synthetic-data-for-program-evaluation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Andrew Heiss: Synthetic Data for Program Evaluation\nDescription: Comprehensive guide for creating synthetic data for DiD, RDD, and IV evaluation designs. Includes R code examples.\nCategory: Causal Inference\nType: Tutorial\nTags: Synthetic Data, Causal Inference, R, Program Evaluation\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:471:uber-gaining-insights-in-a-simulated-marketplace", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Uber: Gaining Insights in a Simulated Marketplace\nDescription: Uber Engineering blog on their agent-based discrete event simulator with GraphSAGE matching for marketplace simulation.\nCategory: Platform Economics\nType: Blog\nTags: Simulation, Marketplace, Agent-Based, Uber\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:472:uber-unleashing-the-power-of-ads-simulation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Uber: Unleashing the Power of Ads Simulation\nDescription: Uber Eats engineering post on building an ads marketplace simulator for testing ad ranking and bidding strategies.\nCategory: Platform Economics\nType: Blog\nTags: Simulation, Advertising, Marketplace, Uber\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:473:lyft-simulating-a-ridesharing-marketplace", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Lyft: Simulating a Ridesharing Marketplace\nDescription: Lyft engineering blog on counterfactual simulation framework for rideshare marketplace optimization.\nCategory: Platform Economics\nType: Blog\nTags: Simulation, Rideshare, Counterfactual, Lyft\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:474:lyft-causal-forecasting-at-lyft", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Lyft: Causal Forecasting at Lyft\nDescription: Two-part series on DAG-based structural modeling and causal forecasting for marketplace decisions at Lyft.\nCategory: Causal Inference\nType: Blog\nTags: Causal Inference, DAG, Forecasting, Lyft\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:475:netflix-page-simulator-for-better-offline-metrics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Page Simulator for Better Offline Metrics\nDescription: Netflix Tech Blog on using simulation to test homepage recommendations before running A/B tests.\nCategory: A/B Testing\nType: Blog\nTags: Simulation, Recommendations, A/B Testing, Netflix\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:476:netflix-quasi-experimentation-at-netflix", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Netflix: Quasi Experimentation at Netflix\nDescription: Netflix Tech Blog covering synthetic control and difference-in-differences methods for observational causal inference.\nCategory: Causal Inference\nType: Blog\nTags: Synthetic Control, DiD, Causal Inference, Netflix\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:477:airbnb-learning-market-dynamics-for-optimal-pricing", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Airbnb: Learning Market Dynamics for Optimal Pricing\nDescription: Airbnb Engineering post combining ML and structural modeling for Smart Pricing. Shows simulation-based approach to pricing.\nCategory: Platform Economics\nType: Blog\nTags: Pricing, Dynamic Pricing, Marketplace, Airbnb\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:478:stable-baselines3-documentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Stable-Baselines3 Documentation\nDescription: Official documentation and tutorials for Stable-Baselines3 reinforcement learning library covering PPO, SAC, DQN implementations.\nCategory: Machine Learning\nType: Tutorial\nTags: Reinforcement Learning, PyTorch, PPO, DQN\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:479:gymnasium-documentation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Gymnasium Documentation\nDescription: Official Farama Foundation documentation for Gymnasium RL environments including tutorials on building custom environments.\nCategory: Machine Learning\nType: Tutorial\nTags: Reinforcement Learning, Environments, OpenAI Gym\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:480:mesa-documentation-tutorials", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Mesa Documentation Tutorials\nDescription: Official Mesa ABM framework tutorials covering model building, data collection, and visualization step-by-step.\nCategory: Computational Economics\nType: Tutorial\nTags: Mesa, Agent-Based Modeling, Python, Tutorial\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:481:eth-zurich-agent-based-modeling-of-economic-systems", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: ETH Zurich: Agent-Based Modeling of Economic Systems\nDescription: GitHub repository with course materials for ETH's ABM course using Mesa. Includes exercises on market simulation and network effects.\nCategory: Computational Economics\nType: Course\nTags: Agent-Based Modeling, Mesa, ETH, Economics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:482:awesome-quant", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Awesome Quant\nDescription: Curated list of quantitative finance libraries and resources (many statistical/TS tools overlap with econometrics).\nCategory: Quantitative Finance\nType: Guide\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:483:the-missing-semester-of-your-cs-education-mit", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: The Missing Semester of Your CS Education (MIT)\nDescription: Teaches essential developer tools often skipped in formal education\u2014command line, Git, Vim, scripting, debugging, etc.\nCategory: Programming\nType: Course\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:484:quantecon-lectures", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: QuantEcon Lectures\nDescription: High-quality lecture series on quantitative economic modeling, computational tools, and economics using Python/Julia.\nCategory: Econometrics\nType: Course\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:485:coding-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Coding for Economists\nDescription: Practical guide by A. Turrell on using Python for modern econometric research, data analysis, and workflows.\nCategory: Programming\nType: Course\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:486:first-course-in-causal-inference-python", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: First Course in Causal Inference (Python)\nDescription: Python implementation of Peng Ding's textbook 'A First Course in Causal Inference'. Educational resource with code examples.\nCategory: Causal Inference\nType: Book\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:487:machine-learning-specialization-coursera", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Machine Learning Specialization (Coursera)\nDescription: Beginner-friendly 3-course series by Andrew Ng covering core ML methods (regression, classification, clustering, trees, NN) with hands-on projects.\nCategory: Machine Learning\nType: Course\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:488:beyond-jupyter-transferlab", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Beyond Jupyter (TransferLab)\nDescription: Teaches software design principles for ML\u2014modularity, abstraction, and reproducibility\u2014going beyond ad hoc Jupyter workflows. Focus on maintainable, production-quality ML code.\nCategory: Programming\nType: Course\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:489:deep-learning-specialization-coursera", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Deep Learning Specialization (Coursera)\nDescription: Intermediate 5-course series by Andrew Ng covering deep neural networks, CNNs, RNNs, transformers, and real-world DL applications using TensorFlow.\nCategory: Machine Learning\nType: Course\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:490:awesome-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Awesome Economics\nDescription: Curated list of economics resources including datasets, software, courses, and blogs.\nCategory: Econometrics\nType: Guide\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "resource:491:google-notebooklm", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Google NotebookLM\nDescription: AI-powered research notebook that auto-generates podcasts and summaries from uploaded research papers and documents.\nCategory: LLMs & Agents\nType: Tool\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:56:fundamentals-of-power-system-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Fundamentals of Power System Economics\nDescription: Bridges engineering and economics for power systems. Assumes no prior economics knowledge. Covers microeconomics, market organization, ancillary services, and renewable integration.\nCategory: Energy & Utilities Economics\nType: Book\nTags: Energy, Economics, Power Systems, Textbook\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:57:international-energy-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: International Energy Markets\nDescription: Definitive textbook covering oil, coal, natural gas, and electricity markets with practical models and institutional context. Author received IAEE Outstanding Contributions Award.\nCategory: Energy & Utilities Economics\nType: Book\nTags: Energy, Markets, Comprehensive, Textbook\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:58:how-solar-energy-became-cheap", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: How Solar Energy Became Cheap\nDescription: Documents the policy, technological, and market dynamics behind solar's 99% cost decline. Essential for understanding technology learning curves and clean energy innovation.\nCategory: Energy & Utilities Economics\nType: Book\nTags: Energy, Solar, Innovation, History\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:59:spot-pricing-of-electricity", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Spot Pricing of Electricity\nDescription: The original book proposing real-time pricing and what became LMP-based markets. Foundational work that influenced all modern wholesale electricity market designs.\nCategory: Energy & Utilities Economics\nType: Book\nTags: Energy, Pricing, Classic, Foundational\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:83:machine-learning-for-economics-and-finance-in-tensorflow-2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Machine Learning for Economics and Finance in TensorFlow 2\nDescription: Applied ML for economists using TensorFlow. Covers portfolio choice, asset pricing, structural estimation, and macroeconomic applications.\nCategory: Machine Learning\nType: Book\nTags: Machine Learning, TensorFlow, Economics, Finance\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:84:business-data-science", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Business Data Science\nDescription: Combining machine learning and economics for applied business problems. Written by former Amazon Chief Economist covering causal inference, experiments, and ML.\nCategory: Machine Learning\nType: Book\nTags: Machine Learning, Business Analytics, Causal Inference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:85:causal-inference-and-machine-learning-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Inference and Machine Learning for Economists\nDescription: Modern treatment of causal ML methods for economists. Free HTML version available online at causalmlbook.com.\nCategory: Machine Learning\nType: Book\nTags: Machine Learning, Causal Inference, Econometrics, Free\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:86:agent-based-and-individual-based-modeling-a-practical-introduction", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Agent-Based and Individual-Based Modeling: A Practical Introduction\nDescription: The standard textbook for agent-based modeling. Second edition covers model design, NetLogo programming, ODD protocol, and analysis techniques.\nCategory: Computational Economics\nType: Book\nTags: Agent-Based Modeling, NetLogo, Simulation, Textbook\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:87:growing-artificial-societies-social-science-from-the-bottom-up", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Growing Artificial Societies: Social Science from the Bottom Up\nDescription: Foundational text on computational social science introducing the Sugarscape model. Shows how trade, conflict, and social dynamics emerge from simple agent rules.\nCategory: Computational Economics\nType: Book\nTags: Agent-Based Modeling, Complexity, Emergence, Classic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:88:handbook-of-computational-economics-vol-2-agent-based-computational-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Handbook of Computational Economics Vol. 2: Agent-Based Computational Economics\nDescription: Comprehensive reference on agent-based computational economics. Covers ACE methodology, financial markets, labor markets, and policy analysis.\nCategory: Computational Economics\nType: Book\nTags: Agent-Based Modeling, Computational Economics, Handbook, Reference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:89:monte-carlo-methods-in-financial-engineering", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Monte Carlo Methods in Financial Engineering\nDescription: Definitive text on Monte Carlo simulation for derivatives pricing and risk management. Covers variance reduction, quasi-Monte Carlo, and Greeks estimation.\nCategory: Pricing & Market Design\nType: Book\nTags: Monte Carlo, Finance, Derivatives, Simulation\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:90:monte-carlo-simulation-for-econometricians", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Monte Carlo Simulation for Econometricians\nDescription: Practical guide to Monte Carlo methods for econometric analysis. Covers estimator evaluation, inference validation, and simulation design for applied research.\nCategory: Econometrics\nType: Book\nTags: Monte Carlo, Econometrics, Simulation, Inference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:91:causal-inference-in-python", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Inference in Python\nDescription: O'Reilly book on applying causal inference in Python. Covers randomized experiments, regression, matching, instrumental variables, DiD, synthetic control, and double ML with practical code examples.\nCategory: Causal Inference & ML\nType: Book\nTags: Causal Inference, Python, DiD, Synthetic Control, Double ML\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "book:92:causal-inference-for-statistics-social-and-biomedical-sciences", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching learning resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Causal Inference for Statistics, Social, and Biomedical Sciences\nDescription: Authoritative textbook on causal inference from the potential outcomes perspective. Covers randomization, matching, propensity scores, instrumental variables, and regression discontinuity.\nCategory: Causal Inference & ML\nType: Book\nTags: Causal Inference, Potential Outcomes, Rubin, Classic\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"python-basics\", \"linear-regression\", etc.],\n  \"topic_tags\": [\"causal-inference\", \"machine-learning\", \"statistics\", etc.],\n  \"summary\": \"2-3 sentences: What will you learn? Who is this for?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"content_format\": \"article|tutorial|course|video|book|newsletter\",\n  \"estimated_duration\": \"Only if inferable from description, else null\",\n  \"skill_progression\": [\"skills you'll gain based on description\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this LEARNING RESOURCE, include:\n- Topics and concepts covered in detail\n- Teaching approach and pedagogy\n- Prerequisites and assumed knowledge\n- Learning outcomes and skills gained\n- Hands-on exercises or projects included\n- How it compares to other learning paths\n- Best audience (students, practitioners, career changers)\n- How long it takes to complete\n- What you can do after finishing this resource\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:251:paul-krugman-erik-brynjolfsson-how-should-we-think-about-the-economics-of-ai", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Paul Krugman & Erik Brynjolfsson: How Should We Think About the Economics of AI?\nDescription: Nobel laureate Paul Krugman interviews Erik Brynjolfsson on AI's economic implications, productivity paradoxes, and future of work.\nCategory: Strategy & Digital Platforms\nType: Podcast\nTags: AI, Economics, Productivity, Future of Work\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:252:daron-acemoglu-on-ai-capitalism-and-freedom", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Daron Acemoglu on AI (Capitalism and Freedom)\nDescription: MIT economist Daron Acemoglu discusses AI's impact on labor markets, inequality, and economic growth on the Capitalism and Freedom podcast.\nCategory: Strategy & Digital Platforms\nType: Interview\nTags: AI, Labor Economics, Inequality, MIT\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:253:richmond-fed-interview-with-anton-korinek", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Richmond Fed Interview with Anton Korinek\nDescription: Econ Focus interview on generative AI for economic research, use cases, and implications for the profession.\nCategory: Strategy & Digital Platforms\nType: Interview\nTags: AI, LLM, Economics Research, Federal Reserve\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:254:rob-axtell-the-tipping-point-for-agent-based-modeling", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Rob Axtell: The Tipping Point for Agent-Based Modeling\nDescription: Flux Podcast interview with Rob Axtell on the evolution of ABM, its applications in economics and social science, and practical advice for modelers.\nCategory: Strategy & Digital Platforms\nType: Podcast\nTags: Agent-Based Modeling, Complexity, Economics, Social Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:255:susan-athey-machine-learning-methods-for-causal-inference-nber", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Susan Athey: Machine Learning Methods for Causal Inference (NBER)\nDescription: NBER Summer Institute lecture on bandits, policy learning, and causal ML methods. Comprehensive overview of modern causal ML tools.\nCategory: Causal Inference & ML\nType: Video\nTags: Causal Inference, Machine Learning, NBER, Methods\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:256:matheus-facure-causal-inference-in-banking-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Matheus Facure: Causal Inference in Banking (UChicago Guest Lecture)\nDescription: Nubank data scientist and author of 'Causal Inference for the Brave and True' on applying causal methods in fintech and banking.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Banking, Fintech, Nubank, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:257:apoorva-lal-causal-econometrics-in-tech-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Apoorva Lal: Causal Econometrics in Tech (UChicago Guest Lecture)\nDescription: Netflix research scientist on applying econometric methods for causal inference in streaming and tech platforms.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Econometrics, Netflix, Tech, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:258:wenjing-zheng-applications-of-causal-machine-learning-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Wenjing Zheng: Applications of Causal Machine Learning (UChicago Guest Lecture)\nDescription: Meta research scientist on practical applications of causal ML methods in large-scale tech systems.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Machine Learning, Meta, Tech, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:259:huigang-chen-estimating-network-effects-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Huigang Chen: Estimating Network Effects (UChicago Guest Lecture)\nDescription: Snap research scientist on methods for estimating network effects and interference in social platforms.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Network Effects, Snap, Experimentation, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:260:jing-pan-ad-measurement-causal-ml-at-snap-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Jing Pan: Ad Measurement & Causal ML at Snap (UChicago Guest Lecture)\nDescription: Snap data scientist on causal methods for advertising measurement and attribution in digital platforms.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Ad Measurement, Attribution, Snap, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:261:sourav-sinha-causal-inference-in-multi-sided-marketplaces-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Sourav Sinha: Causal Inference in Multi-Sided Marketplaces (UChicago Guest Lecture)\nDescription: Lyft data scientist on causal inference challenges in ride-sharing and multi-sided marketplace platforms.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Marketplaces, Lyft, Ride-sharing, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:262:totte-harinen-three-fallacies-of-applied-causal-inference-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Totte Harinen: Three Fallacies of Applied Causal Inference (UChicago Guest Lecture)\nDescription: Toyota Research Institute scientist on common pitfalls and fallacies practitioners encounter when applying causal inference methods.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Best Practices, Toyota, Pitfalls, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "talk:263:kevin-mercurio-applied-causal-inference-at-netflix-uchicago-guest-lecture", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching talk/podcast metadata for tech-econ.org.\n\nTALK:\nName: Kevin Mercurio: Applied Causal Inference at Netflix (UChicago Guest Lecture)\nDescription: Netflix data scientist on practical causal inference applications for content recommendation and platform optimization.\nCategory: Causal Inference & ML\nType: Lecture\nTags: Causal Inference, Netflix, Recommendations, Platform, UChicago\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"industry-insights\", \"career-advice\", etc.],\n  \"summary\": \"2-3 sentences: What's discussed? Key takeaways?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why watch/listen to this\"],\n  \"speaker_expertise\": [\"areas mentioned in description\"],\n  \"key_insights\": [\"Only insights explicitly mentioned in description\"],\n  \"mentioned_tools\": [\"Only tools/methods explicitly mentioned\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this TALK/PODCAST/VIDEO, include:\n- Main topics and themes discussed\n- Key insights and takeaways\n- Speaker's perspective and expertise\n- Industry or academic context\n- Practical advice or recommendations shared\n- Questions answered or raised\n- Relevance to different audience segments\n- How it fits in the broader discourse\n- Why someone would watch/listen to this\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:270:nvidia", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: NVIDIA\nDescription: Career portal\nCategory: Company Lists\nTags: hardware, AI, GPU\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:272:intel", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Intel\nDescription: Career portal\nCategory: Company Lists\nTags: hardware, semiconductor\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:273:qualcomm", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Qualcomm\nDescription: Career portal\nCategory: Company Lists\nTags: hardware, mobile\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:280:spotify", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Spotify\nDescription: Career portal\nCategory: Company Lists\nTags: Europe, Sweden, experimentation, economist-title\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:290:supercell", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Supercell\nDescription: Career portal\nCategory: Company Lists\nTags: Europe, Finland, gaming\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:362:notion", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Notion\nDescription: Career portal\nCategory: Company Lists\nTags: productivity\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:449:cvs-health", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: CVS Health\nDescription: Career portal\nCategory: Company Lists\nTags: pharmacy, economist-title, pricing\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:532:revolut", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Revolut\nDescription: Career portal\nCategory: Company Lists\nTags: neobank, causal-inference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:533:n26", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: N26\nDescription: Career portal\nCategory: Company Lists\nTags: neobank, causal-inference\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:541:upstart", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Upstart\nDescription: Career portal\nCategory: Company Lists\nTags: lending, credit-risk\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "career:607:hopper", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching career resource metadata for tech-econ.org.\n\nRESOURCE:\nName: Hopper\nDescription: Career portal\nCategory: Company Lists\nTags: ota, price-prediction\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"interview-prep\", \"salary-negotiation\", \"job-search\", etc.],\n  \"summary\": \"2-3 sentences: What career advice does this provide?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries about career topics\"],\n  \"use_cases\": [\"when to use this resource\"],\n  \"role_type\": [\"data-scientist\", \"economist\", \"ML-engineer\", etc.],\n  \"experience_level\": \"entry|mid|senior|executive\",\n  \"company_context\": [\"Only if mentioned: FAANG, startup, finance, etc.\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CAREER RESOURCE, include:\n- Career paths and roles discussed\n- Skills and qualifications emphasized\n- Industry and company context\n- Interview preparation content\n- Salary and compensation insights (if any)\n- Day-to-day job responsibilities covered\n- Career progression and growth paths\n- Networking and job search strategies\n- Common challenges and how to overcome them\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:49:isms-marketing-science-conference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: ISMS Marketing Science Conference\nDescription: Premier academic marketing venue with 12+ parallel tracks over 2.5 days. Topics span choice models, game theory, structural econometric models, randomized control trials, pricing, advertising effectiveness, and causal inference.\nCategory: Conferences\nType: Annual Conference\nLocation: Washington DC (2025)\nTags: Conferences, Marketing Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:54:informs-revenue-management-and-pricing-conference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: INFORMS Revenue Management and Pricing Conference\nDescription: Premier forum for pricing analytics held at top business schools. Topics include dynamic pricing, demand forecasting, optimization algorithms, marketplace design, and algorithmic pricing.\nCategory: Conferences\nType: Annual Conference\nLocation: Columbia (2025)\nTags: Conferences, Pricing & Revenue\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:55:msom-conference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: MSOM Conference\nDescription: Manufacturing and Service Operations Management conference covering service operations, platform operations, sharing economy research, and the operations-finance interface.\nCategory: Conferences\nType: Annual Conference\nLocation: London Business School (2025)\nTags: Conferences, Pricing & Revenue\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:71:ashecon-american-society-of-health-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: ASHEcon (American Society of Health Economists)\nDescription: Premier US health economics research conference across 180+ sessions. Features theoretical and empirical research on healthcare costs, insurance, pharmaceuticals, and policy with applied analytics including claims data analysis.\nCategory: Conferences\nType: Annual Conference\nLocation: Nashville (2025), Minneapolis (2026)\nTags: Conferences, Healthcare Economics\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:103:arf-marketing-analytics-accelerator", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: ARF Marketing Analytics Accelerator\nDescription: Flagship audience measurement conference with peer-reviewed research on cross-platform measurement, attention metrics, and AI in advertising. Premier venue for advertising researchers.\nCategory: Conferences\nType: Annual Conference\nLocation: New York, NY\nTags: Conferences, Marketing Science\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:110:informs-tsl-workshop", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: INFORMS TSL Workshop\nDescription: INFORMS Transportation Science and Logistics workshop focusing on ML and OR for transportation optimization. Academic-focused with strong methods content.\nCategory: Conferences\nType: Annual Workshop\nLocation: Seoul, Korea (2025)\nTags: Conferences, Supply Chain\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:222:informs-communities", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: INFORMS Communities\nDescription: Operations research community with specialized groups: Revenue Management & Pricing Section, Decision Analysis Section, Analytics Section, Junior Faculty Interest Group. Membership ~$170/year. Annual Meeting and Analytics Conference are premier networking events.\nCategory: Online\nType: Professional Association\nLocation: Online\nTags: Online, Professional Association\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:255:informs-san-francisco-chapter", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: INFORMS San Francisco Chapter\nDescription: Monthly meetups for operations research and analytics professionals.\nCategory: Meetups\nType: San Francisco\nLocation: San Francisco, CA\nTags: Meetups, San Francisco\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:261:informs-pnw-chapter", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: INFORMS PNW Chapter\nDescription: Pacific Northwest operations research chapter. Regular events for OR professionals.\nCategory: Meetups\nType: Seattle\nLocation: Seattle, WA\nTags: Meetups, Seattle\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:329:michael-luca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: Michael Luca\nDescription: PhD Harvard. Lee J. Styslinger III Associate Professor at Harvard Business School. Research on platform design and data-driven decision making. Ongoing collaborations with Yelp, Facebook, UK government. Co-authored seminal 'Economists in Tech Companies' paper with Susan Athey.\nCategory: Leading Lights\nType: Professor & Advisor\nLocation: Boston, MA\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:351:sangeet-paul-choudary", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: Sangeet Paul Choudary\nDescription: Co-author of Platform Revolution. Founder of Platform Thinking Labs. Advisor on platform strategy and digital transformation.\nCategory: Notable Contributors\nType: Industry Leader\nLocation: Singapore\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:403:thomas-wiecki", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: Thomas Wiecki\nDescription: Co-creator of PyMC and CEO of PyMC Labs. Provides strategic thought leadership on Bayesian approaches for marketing measurement.\nCategory: Notable Contributors\nType: Industry Leader\nLocation: Germany\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:406:michael-kaminsky", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: Michael Kaminsky\nDescription: Co-CEO of Recast, former Director of Analytics at Harry's where he built their internal MMM. Essential thinking on MMM verification and organizational adoption.\nCategory: Notable Contributors\nType: Industry Leader\nLocation: USA\nTags: \n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:429:usaee-iaee-north-american-conference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: USAEE/IAEE North American Conference\nDescription: Largest gathering of U.S. energy economists with student paper competitions, networking, and presentations on electricity, oil/gas, and environmental economics.\nCategory: Conferences\nType: Annual Conference\nLocation: Various US cities\nTags: Energy, Economics, Academic, Student\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:430:power-conference-berkeley", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: POWER Conference (Berkeley)\nDescription: Annual one-day conference at UC Berkeley featuring leading electricity economics researchers including Borenstein, Wolak, Allcott, and Fowlie. Focused on power sector research.\nCategory: Conferences\nType: Annual Conference\nLocation: Berkeley, CA\nTags: Energy, Electricity, Academic, Research\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:446:nber-economics-of-ai-conference", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: NBER Economics of AI Conference\nDescription: Annual NBER conference on the economics of artificial intelligence. Leading researchers present on AI's impact on labor, productivity, and economic growth.\nCategory: Conferences\nType: Annual Conference\nLocation: Toronto / Various\nTags: AI, Economics, NBER, Research\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:447:mlesi-machine-learning-in-economics-summer-institute", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: MLESI - Machine Learning in Economics Summer Institute\nDescription: Chicago Booth summer institute bringing leading ML for economics researchers together with advanced graduate students.\nCategory: Conferences\nType: Workshop\nLocation: Chicago Booth\nTags: Machine Learning, Economics, Summer School, Chicago Booth\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:448:sofie-financial-machine-learning-summer-school", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: SoFiE Financial Machine Learning Summer School\nDescription: Yale-hosted summer school on machine learning applications for asset pricing and financial econometrics.\nCategory: Conferences\nType: Workshop\nLocation: Yale School of Management\nTags: Machine Learning, Finance, Yale, Summer School\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "community:449:acm-economics-and-computation-ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching conference/community metadata for tech-econ.org.\n\nEVENT:\nName: ACM Economics and Computation (EC)\nDescription: Premier venue for research at the intersection of economics and computation. Covers market design, mechanism design, and algorithmic game theory.\nCategory: Conferences\nType: Annual Conference\nLocation: Varies (2024: Yale)\nTags: Economics, Computation, Market Design, ACM\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [],\n  \"topic_tags\": [\"networking\", \"academic-conference\", \"industry-event\", etc.],\n  \"summary\": \"2-3 sentences: What is this event? Who attends?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 search queries\"],\n  \"use_cases\": [\"why attend this\"],\n  \"event_format\": \"conference|meetup|workshop|online|hybrid\",\n  \"geographic_focus\": \"Only if location is mentioned, else null\",\n  \"frequency\": \"annual|biannual|quarterly|monthly|one-time\",\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this CONFERENCE/EVENT, include:\n- Event focus and main themes\n- Typical attendee profile\n- Session formats (talks, workshops, networking)\n- Academic vs industry orientation\n- Geographic reach and accessibility\n- Notable tracks or special sessions\n- Networking opportunities\n- What attendees typically gain\n- How it compares to similar events\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:statistics:bayesian-hierarchical-models:0:inferring-causal-impact-using-bayesian-structural-time-series-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Inferring Causal Impact Using Bayesian Structural Time-Series Models\nAuthors: Kay H. Brodersen, Fabian Gallusser, Jim Koehler, Nicolas Remy, Steven L. Scott\nYear: 2015\nDescription: CausalImpact combines Bayesian structural time-series with synthetic control to estimate counterfactual outcomes when experiments are impossible. Answers 'what would have happened without the intervention?' Google's most-used internal causal inference tool for measuring TV campaigns and regional launches.\nTags: Statistics, Bayesian Hierarchical Models\nCitations: 899\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:experimentation:switchback-geo:1:using-synthetic-controls-feasibility-data-requirements-and-methodological-aspect", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects\nAuthors: Alberto Abadie\nYear: 2021\nDescription: Authoritative methodological review from synthetic control's creator; called 'most important innovation in policy evaluation in 15 years'.\nTags: Experimentation, Switchback & Geo-Experiments\nCitations: 1186\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:observational-causal-inference:matching-propensity:2:double-debiased-machine-learning-for-treatment-and-structural-parameters", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Double/Debiased Machine Learning for Treatment and Structural Parameters\nAuthors: Victor Chernozhukov, Denis Chetverikov, Mert Demirer, et al.\nYear: 2018\nDescription: The double ML framework using cross-fitting to obtain valid inference with ML first-stage estimation.\nTags: Observational Causal Inference, Matching & Propensity Scores\nCitations: 1894\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:observational-causal-inference:double-ml-cate:3:estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimation and Inference of Heterogeneous Treatment Effects using Random Forests\nAuthors: Stefan Wager, Susan Athey\nYear: 2018\nDescription: Causal forests for estimating conditional average treatment effects with valid confidence intervals.\nTags: Observational Causal Inference, Double ML & Heterogeneous Effects\nCitations: 2467\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:collaborative-filtering:4:matrix-factorization-techniques-for-recommender-systems", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Matrix Factorization Techniques for Recommender Systems\nAuthors: Yehuda Koren, Robert Bell, Chris Volinsky\nYear: 2009\nDescription: The definitive Netflix Prize paper establishing matrix factorization as the dominant CF paradigm.\nTags: Recommender Systems, Collaborative Filtering & Matrix Factorization\nCitations: 11142\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:deep-recommenders:5:deep-neural-networks-for-youtube-recommendations", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Deep Neural Networks for YouTube Recommendations\nAuthors: Paul Covington, Jay Adams, Emre Sargin\nYear: 2016\nDescription: Seminal industry paper establishing two-stage deep learning (candidate generation + ranking) at billion-scale.\nTags: Recommender Systems, Deep Recommenders\nCitations: 3182\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:deep-recommenders:6:wide-deep-learning-for-recommender-systems", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Wide & Deep Learning for Recommender Systems\nAuthors: Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, Hemal Shah\nYear: 2016\nDescription: Jointly trains wide linear models (memorization) with deep networks (generalization) using shared embeddings. Productionized on Google Play for 1B+ users; seminal industry paper establishing wide+deep paradigm.\nTags: Recommender Systems, Deep Recommenders\nCitations: 3197\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:deep-recommenders:7:deepfm-a-factorization-machine-based-neural-network-for-ctr-prediction", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: DeepFM: A Factorization-Machine based Neural Network for CTR Prediction\nAuthors: Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He\nYear: 2017\nDescription: Combines FM component (low-order interactions) with deep component (high-order) via shared embeddings. Unlike Wide&Deep, requires no manual feature engineering. End-to-end training.\nTags: Recommender Systems, Deep Recommenders\nCitations: 2132\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:deep-recommenders:8:deep-interest-network-for-click-through-rate-prediction", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Deep Interest Network for Click-Through Rate Prediction\nAuthors: Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, Kun Gai\nYear: 2018\nDescription: Attention mechanism adaptively learns user interest representations from behavioral history relative to candidate items\u2014solving fixed-length embedding bottleneck. Deployed on Alibaba main traffic.\nTags: Recommender Systems, Deep Recommenders\nCitations: 1902\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:causal-recommendations:9:unbiased-learning-to-rank-with-biased-feedback", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Unbiased Learning-to-Rank with Biased Feedback\nAuthors: Thorsten Joachims, Adith Swaminathan, Tobias Schnabel\nYear: 2017\nDescription: Addresses position bias in click data; propensity-weighted ranking SVM; essential for implicit feedback.\nTags: Recommender Systems, Causal Recommendations & Debiasing\nCitations: 495\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:recommender-systems:exploration-diversity:10:an-empirical-evaluation-of-thompson-sampling", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: An Empirical Evaluation of Thompson Sampling\nAuthors: Olivier Chapelle, Lihong Li\nYear: 2011\nDescription: Comprehensive evaluation across display advertising and news recommendation demonstrating Thompson Sampling achieves state-of-the-art results; reignited practical interest in TS.\nTags: Recommender Systems, Exploration & Diversity\nCitations: 998\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:reinforcement-learning:contextual-bandits:11:a-contextual-bandit-approach-to-personalized-news-article-recommendation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Contextual-Bandit Approach to Personalized News Article Recommendation\nAuthors: Lihong Li, Wei Chu, John Langford, Robert E. Schapire\nYear: 2010\nDescription: Introduces LinUCB; deployed at Yahoo! with 33M events; foundational industry paper.\nTags: Reinforcement Learning, Contextual Bandits\nCitations: 2403\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:reinforcement-learning:off-policy-evaluation:12:the-self-normalized-estimator-for-counterfactual-learning", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Self-Normalized Estimator for Counterfactual Learning\nAuthors: Adith Swaminathan, Thorsten Joachims\nYear: 2015\nDescription: Addresses high variance in IPS with self-normalization for real systems.\nTags: Reinforcement Learning, Off-Policy Evaluation\nCitations: 200\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:reinforcement-learning:rl-bidding-pricing:13:real-time-bidding-by-reinforcement-learning-in-display-advertising", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Real-Time Bidding by Reinforcement Learning in Display Advertising\nAuthors: Han Cai, Kan Ren, Weinan Zhang et al.\nYear: 2017\nDescription: MDP framework for RTB with neural network value approximation for budget-constrained bidding.\nTags: Reinforcement Learning, RL for Bidding & Pricing\nCitations: 153\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:reinforcement-learning:rl-recommendations:14:top-k-off-policy-correction-for-a-reinforce-recommender-system", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Top-K Off-Policy Correction for a REINFORCE Recommender System\nAuthors: Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, Ed Chi\nYear: 2019\nDescription: Deployed at YouTube; addresses large action spaces in slate recommendation with off-policy correction.\nTags: Reinforcement Learning, RL for Recommendations\nCitations: 366\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:reinforcement-learning:rl-recommendations:15:slateq-a-tractable-decomposition-for-reinforcement-learning-with-recommendation-", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Sets\nAuthors: Eugene Ie, Vihan Jain, Jing Wang, Sanmit Narvekar, Ritesh Agarwal, Rui Wu, Heng-Tze Cheng, Morgane Lustman, Vince Gatto, Paul Covington, Jim McFadden, Tushar Chandra, Craig Boutilier\nYear: 2019\nDescription: Decomposes slate Q-values for tractable optimization; deployed at Google.\nTags: Reinforcement Learning, RL for Recommendations\nCitations: 110\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:revealed-preference:16:conditional-logit-analysis-of-qualitative-choice-behavior", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Conditional Logit Analysis of Qualitative Choice Behavior\nAuthors: Daniel McFadden\nYear: 1974\nDescription: Nobel Prize-winning random utility framework; foundation of discrete choice models used throughout tech.\nTags: Inverse RL & Preference Learning, Revealed Preference at Scale\nCitations: 13967\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:preference-elicitation:17:counterfactual-risk-minimization-learning-from-logged-bandit-feedback", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Counterfactual Risk Minimization: Learning from Logged Bandit Feedback\nAuthors: Adith Swaminathan, Thorsten Joachims\nYear: 2015\nDescription: Propensity-weighted learning from logged actions; foundation for offline policy learning in recommendations.\nTags: Inverse RL & Preference Learning, Preference Elicitation & Active Learning\nCitations: 124\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:choice-modeling:18:an-experimental-comparison-of-click-position-bias-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: An Experimental Comparison of Click Position-Bias Models\nAuthors: Nick Craswell, Onno Zoeter, Michael Taylor, Bill Ramsey\nYear: 2008\nDescription: Seminal click modeling paper; introduced cascade and position-based models; foundation for bias correction.\nTags: Inverse RL & Preference Learning, Choice Modeling from Behavioral Data\nCitations: 935\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:choice-modeling:19:unbiased-learning-to-rank-with-biased-feedback", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Unbiased Learning-to-Rank with Biased Feedback\nAuthors: Thorsten Joachims, Adith Swaminathan, Tobias Schnabel\nYear: 2017\nDescription: Counterfactual framework for unbiased LTR; Propensity-Weighted Ranking SVM; highly influential for debiasing.\nTags: Inverse RL & Preference Learning, Choice Modeling from Behavioral Data\nCitations: 495\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:choice-modeling:20:click-models-for-web-search", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Click Models for Web Search\nAuthors: Aleksandr Chuklin, Ilya Markov, Maarten de Rijke\nYear: 2015\nDescription: Comprehensive survey of click models, estimation methods, and applications to search evaluation.\nTags: Inverse RL & Preference Learning, Choice Modeling from Behavioral Data\nCitations: 260\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:personalization-user-modeling:21:collaborative-filtering-for-implicit-feedback-datasets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Collaborative Filtering for Implicit Feedback Datasets\nAuthors: Yifan Hu, Yehuda Koren, Chris Volinsky\nYear: 2008\nDescription: Weighted matrix factorization for clicks/views; confidence-weighted preference learning; industry standard.\nTags: Inverse RL & Preference Learning, Personalization & User Modeling\nCitations: 3154\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:inverse-rl-preference-learning:personalization-user-modeling:22:bpr-bayesian-personalized-ranking-from-implicit-feedback", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: BPR: Bayesian Personalized Ranking from Implicit Feedback\nAuthors: Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme\nYear: 2009\nDescription: Pairwise ranking optimization from Bayesian principles; first method optimizing ranking directly for implicit data.\nTags: Inverse RL & Preference Learning, Personalization & User Modeling\nCitations: 4304\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:forecasting:causal-impact:23:inferring-causal-impact-using-bayesian-structural-time-series-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Inferring Causal Impact Using Bayesian Structural Time-Series Models\nAuthors: Kay H. Brodersen, Fabian Gallusser, Jim Koehler, Nicolas Remy, Steven L. Scott\nYear: 2015\nDescription: Google's CausalImpact for estimating causal effects from observational time series; widely used for attribution.\nTags: Forecasting, Causal Impact & Intervention\nCitations: 899\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:forecasting:causal-impact:24:synthetic-control-methods-for-comparative-case-studies", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Synthetic Control Methods for Comparative Case Studies\nAuthors: Alberto Abadie, Alexis Diamond, Jens Hainmueller\nYear: 2010\nDescription: Foundational synthetic control paper; 'most important innovation in evaluation literature in 15 years'.\nTags: Forecasting, Causal Impact & Intervention\nCitations: 5029\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:forecasting:causal-impact:25:using-synthetic-controls-feasibility-data-requirements-and-methodological-aspect", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Synthetic Controls: Feasibility, Data Requirements, and Methodological Aspects\nAuthors: Alberto Abadie\nYear: 2021\nDescription: Comprehensive methodological review covering feasibility, inference, and best practices.\nTags: Forecasting, Causal Impact & Intervention\nCitations: 1186\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:forecasting:causal-impact:26:difference-in-differences-with-multiple-time-periods", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Difference-in-Differences with Multiple Time Periods\nAuthors: Brantly Callaway, Pedro H.C. Sant'Anna\nYear: 2021\nDescription: Modern DiD handling staggered treatment timing and heterogeneous effects; doubly-robust estimator.\nTags: Forecasting, Causal Impact & Intervention\nCitations: 1413\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:forecasting:causal-impact:27:what-s-trending-in-difference-in-differences-a-synthesis-of-the-recent-econometr", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: What's Trending in Difference-in-Differences? A Synthesis of the Recent Econometrics Literature\nAuthors: Jonathan Roth, Pedro H.C. Sant'Anna, Alyssa Bilinski, John Poe\nYear: 2023\nDescription: Comprehensive synthesis of modern DiD developments; essential guide to recent methodological advances.\nTags: Forecasting, Causal Impact & Intervention\nCitations: None\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:forecasting:production-systems:28:forecasting-at-scale-prophet", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Forecasting at Scale (Prophet)\nAuthors: Sean J. Taylor, Benjamin Letham\nYear: 2018\nDescription: Meta's production system enabling analysts to create reliable forecasts with domain knowledge.\nTags: Forecasting, Production Forecasting Systems\nCitations: None\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:clustering-segmentation:video-movie-clustering:29:deep-neural-networks-for-youtube-recommendations", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Deep Neural Networks for YouTube Recommendations\nAuthors: Paul Covington et al.\nYear: 2016\nDescription: Two-tower architecture for video clustering and candidate generation at YouTube scale.\nTags: Clustering & Segmentation, Video & Movie Clustering\nCitations: 3182\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:clustering-segmentation:video-movie-clustering:30:matrix-factorization-techniques-for-recommender-systems", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Matrix Factorization Techniques for Recommender Systems\nAuthors: Yehuda Koren, Robert Bell, Chris Volinsky\nYear: 2009\nDescription: Netflix Prize winning approach using latent factors\u2014foundational for content clustering.\nTags: Clustering & Segmentation, Video & Movie Clustering\nCitations: 11142\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:surge-realtime:31:surge-pricing-solves-the-wild-goose-chase", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Surge Pricing Solves the Wild Goose Chase\nAuthors: Juan Castillo, Dan Knoepfle, Glen Weyl\nYear: 2017\nDescription: Empirical analysis of Uber's surge pricing showing welfare improvements from reduced search frictions.\nTags: Pricing, Surge & Real-time Pricing\nCitations: 258\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:surge-realtime:32:the-value-of-flexible-work-evidence-from-uber-drivers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Value of Flexible Work: Evidence from Uber Drivers\nAuthors: M. Keith Chen, Judith Chevalier, Peter Rossi, Emily Oehlsen\nYear: 2019\nDescription: Estimates labor supply elasticity and value of flexibility using Uber driver data.\nTags: Pricing, Surge & Real-time Pricing\nCitations: 352\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:surge-realtime:33:economics-of-a-bottleneck", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Economics of a Bottleneck\nAuthors: Richard Arnott, Andr\u00e9 de Palma, Robin Lindsey\nYear: 1990\nDescription: The workhorse model for dynamic congestion pricing theory\u2014operationalized Vickrey's bottleneck concept with endogenous departure decisions and time-varying tolls.\nTags: Pricing, Surge & Real-time Pricing\nCitations: 641\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:surge-realtime:34:platform-competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Platform Competition in Two-Sided Markets\nAuthors: Jean-Charles Rochet, Jean Tirole\nYear: 2003\nDescription: The foundational paper on two-sided market pricing\u2014derives optimal price allocation explaining why platforms price asymmetrically across sides.\nTags: Pricing, Surge & Real-time Pricing\nCitations: 215\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:surge-realtime:35:competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Competition in Two-Sided Markets\nAuthors: Mark Armstrong\nYear: 2006\nDescription: Introduces the competitive bottlenecks framework where one side multi-homes\u2014explains monopoly power over access to single-homing customers.\nTags: Pricing, Surge & Real-time Pricing\nCitations: 79\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:personalized-pricing:36:the-economics-of-privacy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Economics of Privacy\nAuthors: Alessandro Acquisti, Curtis Taylor, Liad Wagman\nYear: 2016\nDescription: The definitive JEL survey on privacy and personal data economics\u2014covers consumer tracking, welfare implications, and regulatory frameworks.\nTags: Pricing, Personalized Pricing\nCitations: 1057\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:rl-for-pricing:37:a-tutorial-on-thompson-sampling", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Tutorial on Thompson Sampling\nAuthors: Daniel J. Russo, Benjamin Van Roy, Abbas Kazerouni, Ian Osband, Zheng Wen\nYear: 2018\nDescription: Definitive reference on Thompson sampling covering Bernoulli bandits, product recommendation, assortment optimization, and RL in MDPs.\nTags: Pricing, RL for Pricing\nCitations: 489\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:pricing:rl-for-pricing:38:thompson-sampling-for-contextual-bandits-with-linear-payoffs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Thompson Sampling for Contextual Bandits with Linear Payoffs\nAuthors: Shipra Agrawal, Navin Goyal\nYear: 2013\nDescription: First theoretical regret guarantees for contextual Thompson Sampling. Proves \u00d5(d\u221aT) regret bounds. Novel martingale-based analysis became the template for subsequent work.\nTags: Pricing, RL for Pricing\nCitations: 547\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:subscriptions-retention:customer-base-analysis:39:manage-marketing-by-the-customer-equity-test", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Manage Marketing by the Customer Equity Test\nAuthors: Robert C. Blattberg, John Deighton\nYear: 1996\nDescription: Introduces the customer equity concept and decision calculus for balancing acquisition versus retention spending. Origins of viewing customers as assets. Over 1,000 citations; bridges practitioner and academic perspectives.\nTags: Subscriptions & Retention, Customer Base Analysis & Cohort Methods\nCitations: 247\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:subscriptions-retention:customer-base-analysis:40:return-on-marketing-using-customer-equity-to-focus-marketing-strategy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Return on Marketing: Using Customer Equity to Focus Marketing Strategy\nAuthors: Roland T. Rust, Katherine N. Lemon, Valarie A. Zeithaml\nYear: 2004\nDescription: Unified strategic framework enabling marketing options to be traded off based on projected financial return, operationalized as change in customer equity. Key contribution linking marketing decisions to shareholder value through customer equity.\nTags: Subscriptions & Retention, Customer Base Analysis & Cohort Methods\nCitations: 2082\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:subscriptions-retention:customer-base-analysis:41:valuing-customers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Valuing Customers\nAuthors: Sunil Gupta, Donald R. Lehmann, Jennifer Ames Stuart\nYear: 2004\nDescription: Demonstrates how CLV can value firms including high-growth firms with negative earnings. Shows 1% improvement in retention improves firm value by 3-7%, while margin improvement yields only ~1% increase. Validated on Amazon, eBay, Capital One, E*Trade data.\nTags: Subscriptions & Retention, Customer Base Analysis & Cohort Methods\nCitations: 792\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:ad-auctions:42:internet-advertising-and-the-generalized-second-price-auction", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Internet Advertising and the Generalized Second-Price Auction\nAuthors: Benjamin Edelman, Michael Ostrovsky, Michael Schwarz\nYear: 2007\nDescription: Analysis of the GSP auction used by Google and the gap from VCG efficiency.\nTags: Advertising, Ad Auctions (GSP, VCG)\nCitations: 1598\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:ad-auctions:43:position-auctions", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Position Auctions\nAuthors: Hal Varian\nYear: 2007\nDescription: Equilibrium analysis of position auctions with symmetric Nash equilibrium characterization.\nTags: Advertising, Ad Auctions (GSP, VCG)\nCitations: 745\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:ad-auctions:44:counterspeculation-auctions-and-competitive-sealed-tenders", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Counterspeculation, Auctions, and Competitive Sealed Tenders\nAuthors: William Vickrey\nYear: 1961\nDescription: Nobel Prize-winning paper establishing truthful bidding in second-price sealed-bid auctions\u2014the theoretical bedrock for all VCG mechanisms and modern ad auctions. ~8,000 citations.\nTags: Advertising, Ad Auctions (GSP, VCG)\nCitations: 7222\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:ad-auctions:45:optimal-auction-design", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Optimal Auction Design\nAuthors: Roger B. Myerson\nYear: 1981\nDescription: Derives revenue-maximizing auctions and optimal reserve prices via 'virtual value' concept. Essential for understanding how platforms set reserve prices. ~6,400 citations.\nTags: Advertising, Ad Auctions (GSP, VCG)\nCitations: 5977\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:autobidding-pacing:46:learning-in-repeated-auctions-with-budgets-regret-minimization-and-equilibrium", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Learning in Repeated Auctions with Budgets: Regret Minimization and Equilibrium\nAuthors: Santiago R. Balseiro, Yonatan Gur\nYear: 2019\nDescription: Introduces adaptive pacing strategies with asymptotic optimality proofs; shows these form approximate Nash equilibrium. The reference paper for budget pacing algorithms at Google/Meta.\nTags: Advertising, Autobidding & Budget Pacing\nCitations: 27\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:attribution-incrementality:47:ghost-ads-improving-the-economics-of-measuring-online-ad-effectiveness", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Ghost Ads: Improving the Economics of Measuring Online Ad Effectiveness\nAuthors: Garrett Johnson, Randall Lewis, Elmar Nubbemeyer\nYear: 2017\nDescription: Novel methodology for measuring ad lift without holdout using predicted ad exposure.\nTags: Advertising, Attribution & Incrementality\nCitations: 161\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:attribution-incrementality:48:the-unfavorable-economics-of-measuring-the-returns-to-advertising", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Unfavorable Economics of Measuring the Returns to Advertising\nAuthors: Randall A. Lewis, Justin M. Rao\nYear: 2015\nDescription: Analyzes 25 large RCTs ($2.8M spend) showing massive sample sizes needed for reliable ad measurement due to individual sales volatility (CV of 10). Explains why selection bias is 'crippling.' ~700 citations.\nTags: Advertising, Attribution & Incrementality\nCitations: 281\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:targeting-lookalikes:49:targeting-and-privacy-in-mobile-advertising", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Targeting and Privacy in Mobile Advertising\nAuthors: Omid Rafieian, Hema Yoganarasimhan\nYear: 2021\nDescription: Unified framework combining ML-based targeting with auction models; shows efficient targeting improves CTR by 66.8% over current practice, with implications for privacy regulation.\nTags: Advertising, Targeting & Lookalikes\nCitations: 187\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:advertising:privacy-ad-effectiveness:50:privacy-regulation-and-online-advertising", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Privacy Regulation and Online Advertising\nAuthors: Avi Goldfarb, Catherine E. Tucker\nYear: 2011\nDescription: Foundational empirical paper showing EU privacy regulation (ePrivacy Directive) reduced display ad effectiveness by 65% in changing purchase intent. ~2,500 citations.\nTags: Advertising, Privacy & Ad Effectiveness\nCitations: 3\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:network-effects:51:platform-competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Platform Competition in Two-Sided Markets\nAuthors: Jean-Charles Rochet, Jean Tirole\nYear: 2003\nDescription: THE foundational two-sided markets paper; pricing structure, chicken-and-egg dynamics. ~8,000 citations.\nTags: Marketing & Growth, Network Effects & Viral Growth\nCitations: 215\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:network-effects:52:competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Competition in Two-Sided Markets\nAuthors: Mark Armstrong\nYear: 2006\nDescription: Introduces competitive bottlenecks\u2014when one side multi-homes, platforms compete fiercely on single-homers. ~4,500 citations.\nTags: Marketing & Growth, Network Effects & Viral Growth\nCitations: 79\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:marketing-mix:53:bayesian-methods-for-media-mix-modeling-with-carryover-and-shape-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Bayesian Methods for Media Mix Modeling with Carryover and Shape Effects\nAuthors: Yuxue Jin, Yueqing Wang, Yunting Sun, David Chan, Jim Koehler\nYear: 2017\nDescription: Foundational Google paper introducing Bayesian MMM with adstock/saturation curves; basis for LightweightMMM.\nTags: Marketing & Growth, Marketing Mix Modeling\nCitations: 13\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:uplift-modeling:54:estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimation and Inference of Heterogeneous Treatment Effects using Random Forests\nAuthors: Stefan Wager, Susan Athey\nYear: 2018\nDescription: Causal forests for HTE estimation with valid confidence intervals; foundation for grf package; 2000+ citations.\nTags: Marketing & Growth, Uplift Modeling\nCitations: 2467\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:uplift-modeling:55:towards-optimal-doubly-robust-estimation-of-heterogeneous-causal-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Towards Optimal Doubly Robust Estimation of Heterogeneous Causal Effects\nAuthors: Edward H. Kennedy\nYear: 2023\nDescription: DR-learner with minimax optimality bounds for heterogeneous effects. ~100+ citations.\nTags: Marketing & Growth, Uplift Modeling\nCitations: 110\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:ab-testing:56:an-empirical-evaluation-of-thompson-sampling", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: An Empirical Evaluation of Thompson Sampling\nAuthors: Olivier Chapelle, Lihong Li\nYear: 2011\nDescription: Establishes Thompson Sampling as practical standard for explore-exploit in ad optimization. ~1,500 citations.\nTags: Marketing & Growth, A/B Testing & Experimentation\nCitations: 998\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:marketing-growth:ab-testing:57:inferring-causal-impact-using-bayesian-structural-time-series-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Inferring Causal Impact Using Bayesian Structural Time-Series Models\nAuthors: Kay H. Brodersen, Fabian Gallusser, Jim Koehler, Nicolas Remy, Steven L. Scott\nYear: 2015\nDescription: CausalImpact methodology for geo-experiments when individual randomization impossible. ~1,400 citations.\nTags: Marketing & Growth, A/B Testing & Experimentation\nCitations: 899\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:two-sided-markets:58:platform-competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Platform Competition in Two-Sided Markets\nAuthors: Jean-Charles Rochet, Jean Tirole\nYear: 2003\nDescription: Foundational theory introducing price structure vs. price level distinction for platforms.\nTags: Matching & Marketplaces, Two-Sided Markets\nCitations: 215\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:two-sided-markets:59:competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Competition in Two-Sided Markets\nAuthors: Mark Armstrong\nYear: 2006\nDescription: Three canonical models (monopoly, single-homing, competitive bottlenecks); workhorse for policy analysis.\nTags: Matching & Marketplaces, Two-Sided Markets\nCitations: 79\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:two-sided-markets:60:chicken-and-egg-competition-among-intermediation-service-providers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Chicken and Egg: Competition Among Intermediation Service Providers\nAuthors: Bernard Caillaud, Bruno Jullien\nYear: 2003\nDescription: Addresses startup problem and price competition; divide-and-conquer strategies.\nTags: Matching & Marketplaces, Two-Sided Markets\nCitations: 303\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:two-sided-markets:61:a-price-theory-of-multi-sided-platforms", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Price Theory of Multi-Sided Platforms\nAuthors: E. Glen Weyl\nYear: 2010\nDescription: The theoretical gold standard for platform pricing; introduces Spence distortion showing platforms internalize network effects only for marginal users. Essential for welfare analysis.\nTags: Matching & Marketplaces, Two-Sided Markets\nCitations: 59\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:congestion-rationing:62:using-big-data-to-estimate-consumer-surplus-the-case-of-uber", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Big Data to Estimate Consumer Surplus: The Case of Uber\nAuthors: Peter Cohen, Robert Hahn, Jonathan Hall, Steven Levitt, Robert Metcalfe\nYear: 2016\nDescription: Uses surge pricing variation to estimate demand; $6.8B consumer surplus; RDD methodology.\nTags: Matching & Marketplaces, Congestion & Rationing\nCitations: 329\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:gig-economy-labor:63:an-analysis-of-the-labor-market-for-uber-s-driver-partners-in-the-united-states", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: An Analysis of the Labor Market for Uber's Driver-Partners in the United States\nAuthors: Jonathan Hall, Alan Krueger\nYear: 2018\nDescription: First comprehensive Uber labor market analysis using administrative and survey data; foundational descriptive paper on gig work.\nTags: Matching & Marketplaces, Gig Economy & Platform Labor\nCitations: 648\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:gig-economy-labor:64:the-value-of-flexible-work-evidence-from-uber-drivers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Value of Flexible Work: Evidence from Uber Drivers\nAuthors: M. Keith Chen, Judith Chevalier, Peter Rossi, Emily Oehlsen\nYear: 2019\nDescription: Estimates drivers earn more than twice the surplus they would in rigid arrangements; seminal flexibility valuation paper.\nTags: Matching & Marketplaces, Gig Economy & Platform Labor\nCitations: 352\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:matching-marketplaces:dynamic-pricing-marketplaces:65:artificial-intelligence-algorithmic-pricing-and-collusion", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Artificial Intelligence, Algorithmic Pricing, and Collusion\nAuthors: Emilio Calvano, Giacomo Calzolari, Vincenzo Denicol\u00f2, Sergio Pastorello\nYear: 2020\nDescription: Demonstrates Q-learning algorithms autonomously learn collusive strategies; major antitrust implications for platform pricing.\nTags: Matching & Marketplaces, Dynamic Pricing in Marketplaces\nCitations: 483\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:auction-theory:66:counterspeculation-auctions-and-competitive-sealed-tenders", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Counterspeculation, Auctions, and Competitive Sealed Tenders\nAuthors: William Vickrey\nYear: 1961\nDescription: Introduces second-price sealed-bid (Vickrey) auction; establishes truthful bidding as dominant strategy.\nTags: Mechanism Design & Auctions, Auction Theory Foundations\nCitations: 7222\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:auction-theory:67:optimal-auction-design", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Optimal Auction Design\nAuthors: Roger Myerson\nYear: 1981\nDescription: Characterizes revenue-maximizing auctions; introduces virtual valuations and optimal reserves; Nobel Prize work.\nTags: Mechanism Design & Auctions, Auction Theory Foundations\nCitations: 5977\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:auction-theory:68:a-theory-of-auctions-and-competitive-bidding", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Theory of Auctions and Competitive Bidding\nAuthors: Paul Milgrom, Robert Weber\nYear: 1982\nDescription: Introduces affiliated values and linkage principle; shows English auctions reduce winner's curse.\nTags: Mechanism Design & Auctions, Auction Theory Foundations\nCitations: 3781\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:dynamic-auctions:69:budget-management-strategies-in-repeated-auctions", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Budget Management Strategies in Repeated Auctions\nAuthors: Santiago Balseiro, Soo Jin Kim, Mohammad Mahdian, Vahab Mirrokni\nYear: 2021\nDescription: Compares pacing, throttling, and probabilistic strategies; Google research on platform budget management.\nTags: Mechanism Design & Auctions, Dynamic Auctions & Repeated Games\nCitations: 25\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:dynamic-auctions:70:pacing-equilibrium-in-first-price-auction-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Pacing Equilibrium in First Price Auction Markets\nAuthors: Vincent Conitzer, Christian Kroer, Debmalya Panigrahi, Okke Schrijvers, Nicolas Stier-Moses, Eric Sodomka, Christopher Wilkens\nYear: 2022\nDescription: Proves first-price auctions with budget pacing guarantee equilibrium uniqueness and efficient computation; theoretical foundation for industry's second-to-first price transition.\nTags: Mechanism Design & Auctions, Dynamic Auctions & Repeated Games\nCitations: 51\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:dynamic-auctions:71:multiplicative-pacing-equilibria-in-auction-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Multiplicative Pacing Equilibria in Auction Markets\nAuthors: Vincent Conitzer, Christian Kroer, Eric Sodomka, Nicolas Stier-Moses\nYear: 2022\nDescription: Foundational paper proving existence of pacing equilibria for budget-constrained bidders; connects repeated auctions to competitive equilibrium theory.\nTags: Mechanism Design & Auctions, Dynamic Auctions & Repeated Games\nCitations: 21\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:market-design:72:college-admissions-and-the-stability-of-marriage", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: College Admissions and the Stability of Marriage\nAuthors: David Gale, Lloyd Shapley\nYear: 1962\nDescription: Introduces deferred acceptance algorithm; proves existence of stable matchings; Nobel Prize foundation.\nTags: Mechanism Design & Auctions, Market Design\nCitations: 5835\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:market-design:73:kidney-exchange", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Kidney Exchange\nAuthors: Alvin Roth, Tayfun S\u00f6nmez, M. Utku \u00dcnver\nYear: 2004\nDescription: Designs kidney exchange clearinghouses using top trading cycles; Nobel Prize application.\nTags: Mechanism Design & Auctions, Market Design\nCitations: 617\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:sponsored-search-ad-auctions:74:position-auctions", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Position Auctions\nAuthors: Hal Varian\nYear: 2007\nDescription: Independent equilibrium analysis of search auctions; introduces quality-weighted ranking (bid \u00d7 CTR); validates theory with Google data.\nTags: Mechanism Design & Auctions, Sponsored Search & Display Ad Auctions\nCitations: 745\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:mechanism-design-auctions:sponsored-search-ad-auctions:75:reserve-prices-in-internet-advertising-auctions-a-field-experiment", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Reserve Prices in Internet Advertising Auctions: A Field Experiment\nAuthors: Michael Ostrovsky, Michael Schwarz\nYear: 2023\nDescription: First large-scale field experiment applying Myerson optimal auction theory to sponsored search at Yahoo; demonstrates ~12% revenue increase from optimized reserves.\nTags: Mechanism Design & Auctions, Sponsored Search & Display Ad Auctions\nCitations: 34\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:demand-estimation-blp:76:estimating-discrete-choice-models-of-product-differentiation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimating Discrete-Choice Models of Product Differentiation\nAuthors: Steven T. Berry\nYear: 1994\nDescription: Introduces market share inversion mapping observed shares to mean utilities, enabling IV estimation with aggregate data.\nTags: Structural Estimation, Demand Estimation (BLP)\nCitations: 2959\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:entry-competition:77:estimation-of-a-model-of-entry-in-the-airline-industry", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimation of a Model of Entry in the Airline Industry\nAuthors: Steven Berry\nYear: 1992\nDescription: Methods for estimating discrete games with multiple equilibria; foundation for airline entry applications.\nTags: Structural Estimation, Entry & Competition\nCitations: 1025\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:entry-competition:78:the-welfare-effects-of-peer-entry-the-case-of-airbnb-and-the-accommodation-indus", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Welfare Effects of Peer Entry: The Case of Airbnb and the Accommodation Industry\nAuthors: Chiara Farronato, Andrey Fradkin\nYear: 2022\nDescription: Structural model of competition between 'flexible' peer suppliers (Airbnb) and 'dedicated' sellers (hotels). Finds Airbnb generated $41 consumer surplus per room-night with welfare gains concentrated during capacity-constrained periods.\nTags: Structural Estimation, Entry & Competition\nCitations: 81\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:auction-estimation:79:internet-advertising-and-the-generalized-second-price-auction-selling-billions-o", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Internet Advertising and the Generalized Second-Price Auction: Selling Billions of Dollars Worth of Keywords\nAuthors: Benjamin Edelman, Michael Ostrovsky, Michael Schwarz\nYear: 2007\nDescription: Foundational analysis of GSP auction mechanism used by Google and Yahoo; characterizes equilibria and proves revenue equivalence under complete information. Required reading for ad auction design.\nTags: Structural Estimation, Auction Estimation\nCitations: 1598\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:platform-network-effects:80:two-sided-markets-a-progress-report", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Two-Sided Markets: A Progress Report\nAuthors: Jean-Charles Rochet, Jean Tirole\nYear: 2006\nDescription: Canonical theoretical framework defining two-sided markets where price structure (not just level) matters; establishes concepts of membership fees, usage fees, and indirect network effects.\nTags: Structural Estimation, Platform & Network Effects Estimation\nCitations: 2935\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:platform-network-effects:81:a-price-theory-of-multi-sided-platforms", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Price Theory of Multi-Sided Platforms\nAuthors: E. Glen Weyl\nYear: 2010\nDescription: General theory of monopoly platform pricing showing platforms internalize only marginal users' externalities (Spence distortion). Essential for understanding market power measurement in platform markets.\nTags: Structural Estimation, Platform & Network Effects Estimation\nCitations: 59\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:ecommerce-online-retail:82:consumer-price-search-and-platform-design-in-internet-commerce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Consumer Price Search and Platform Design in Internet Commerce\nAuthors: Michael Dinerstein, Liran Einav, Jonathan Levin, Neel Sundaresan\nYear: 2018\nDescription: Equilibrium model of search and price competition on eBay; quantifies platform design trade-offs between match quality and price competition using detailed browsing data.\nTags: Structural Estimation, E-commerce & Online Retail\nCitations: 209\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:structural-estimation:ml-structural-estimation:83:double-debiased-machine-learning-for-treatment-and-structural-parameters", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Double/Debiased Machine Learning for Treatment and Structural Parameters\nAuthors: Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins\nYear: 2018\nDescription: Foundational framework for using ML to estimate nuisance parameters while preserving valid inference on structural parameters through orthogonal scores and cross-fitting.\nTags: Structural Estimation, Machine Learning & Structural Estimation\nCitations: 1894\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:discrete-choice:84:conditional-logit-analysis-of-qualitative-choice-behavior", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Conditional Logit Analysis of Qualitative Choice Behavior\nAuthors: Daniel McFadden\nYear: 1974\nDescription: Foundational paper deriving multinomial logit from random utility maximization; established modern discrete choice.\nTags: Choice Models & Dynamic Choice, Discrete Choice (Logit, Mixed Logit)\nCitations: 13967\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:discrete-choice:85:automobile-prices-in-market-equilibrium", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Automobile Prices in Market Equilibrium\nAuthors: Steven Berry, James Levinsohn, Ariel Pakes\nYear: 1995\nDescription: Random coefficients demand with market-level data; workhorse for IO and empirical demand.\nTags: Choice Models & Dynamic Choice, Discrete Choice (Logit, Mixed Logit)\nCitations: 4952\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:discrete-choice:86:mixed-mnl-models-for-discrete-response", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Mixed MNL Models for Discrete Response\nAuthors: Daniel McFadden, Kenneth Train\nYear: 2000\nDescription: Proves mixed logit approximates any random utility model; establishes simulation-based estimation.\nTags: Choice Models & Dynamic Choice, Discrete Choice (Logit, Mixed Logit)\nCitations: 3943\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:discrete-choice:87:valuing-new-goods-in-a-model-with-complementarity-online-newspapers", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Valuing New Goods in a Model with Complementarity: Online Newspapers\nAuthors: Matthew Gentzkow\nYear: 2007\nDescription: Mixed logit applied to digital products; estimates substitution between print and online news with cannibalization implications.\nTags: Choice Models & Dynamic Choice, Discrete Choice (Logit, Mixed Logit)\nCitations: 519\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:consideration-sets:88:the-power-of-rankings-quantifying-the-effect-of-rankings-on-online-consumer-sear", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Power of Rankings: Quantifying the Effect of Rankings on Online Consumer Search and Purchase Decisions\nAuthors: Raluca M. Ursu\nYear: 2018\nDescription: Uses Expedia field experiment to causally identify position effects; shows rankings affect search behavior but not purchase conditional on search.\nTags: Choice Models & Dynamic Choice, Consideration Sets & Attention\nCitations: 297\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:dynamic-discrete-choice:89:conditional-choice-probabilities-and-the-estimation-of-dynamic-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Conditional Choice Probabilities and the Estimation of Dynamic Models\nAuthors: V. Joseph Hotz, Robert A. Miller\nYear: 1993\nDescription: CCP estimation recovering value functions without solving the full DP problem.\nTags: Choice Models & Dynamic Choice, Dynamic Discrete Choice\nCitations: 1031\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:search-sequential-choice:90:using-price-distributions-to-estimate-search-costs", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Price Distributions to Estimate Search Costs\nAuthors: Han Hong, Matthew Shum\nYear: 2006\nDescription: Develops methodology to estimate search cost distributions from equilibrium price data alone; identification from search model restrictions.\nTags: Choice Models & Dynamic Choice, Search & Sequential Choice\nCitations: 342\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:search-sequential-choice:91:testing-models-of-consumer-search-using-data-on-web-browsing-and-purchasing-beha", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Testing Models of Consumer Search Using Data on Web Browsing and Purchasing Behavior\nAuthors: Babi\u0307r De Los Santos, Ali Horta\u00e7su, Matthijs R. Wildenbeest\nYear: 2012\nDescription: Uses e-commerce clickstream data to test sequential vs. fixed-sample search; estimates search costs in online book market.\nTags: Choice Models & Dynamic Choice, Search & Sequential Choice\nCitations: 459\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:switching-costs-lock-in:92:state-dependence-and-alternative-explanations-for-consumer-inertia", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: State Dependence and Alternative Explanations for Consumer Inertia\nAuthors: Jean-Pierre Dub\u00e9, G\u00fcnter J. Hitsch, Peter E. Rossi\nYear: 2010\nDescription: Demonstrates identification of structural state dependence from spurious heterogeneity using flexible semi-parametric methods; distinguishes true loyalty from heterogeneity.\nTags: Choice Models & Dynamic Choice, Switching Costs & Platform Lock-in\nCitations: 362\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:switching-costs-lock-in:93:competition-in-two-sided-markets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Competition in Two-Sided Markets\nAuthors: Mark Armstrong\nYear: 2006\nDescription: Foundational model distinguishing single-homing from multi-homing; introduces 'competitive bottlenecks' explaining platform lock-in dynamics.\nTags: Choice Models & Dynamic Choice, Switching Costs & Platform Lock-in\nCitations: 79\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:choice-models-dynamic-choice:social-influence-peer-effects:94:creating-social-contagion-through-viral-product-design-a-randomized-trial-of-pee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Creating Social Contagion Through Viral Product Design: A Randomized Trial of Peer Influence in Networks\nAuthors: Sinan Aral, Dylan Walker\nYear: 2011\nDescription: Landmark RCT with 1.4 million Facebook users identifying causal peer influence; passive-broadcast features generate 246% increase in peer adoption.\nTags: Choice Models & Dynamic Choice, Social Influence & Peer Effects\nCitations: 625\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:credit-lending:pricing-credit:95:estimating-welfare-in-insurance-markets-using-variation-in-prices", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimating Welfare in Insurance Markets Using Variation in Prices\nAuthors: Liran Einav, Amy Finkelstein, Mark R. Cullen\nYear: 2010\nDescription: Demand-and-cost curve framework for analyzing selection; widely applied to credit markets.\nTags: Credit & Lending, Pricing Credit Products\nCitations: 90\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:credit-lending:pricing-credit:96:selection-in-insurance-markets-theory-and-empirics-in-pictures", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Selection in Insurance Markets: Theory and Empirics in Pictures\nAuthors: Liran Einav, Amy Finkelstein\nYear: 2011\nDescription: Intuitive graphical framework for understanding selection and welfare in credit/insurance.\nTags: Credit & Lending, Pricing Credit Products\nCitations: 333\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:credit-lending:platform-trust-safety:97:the-limits-of-reputation-in-platform-markets-an-empirical-analysis-and-field-exp", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Limits of Reputation in Platform Markets: An Empirical Analysis and Field Experiment\nAuthors: Chris Nosko, Steven Tadelis\nYear: 2015\nDescription: Field experiment showing reputation inflation and limits of feedback systems.\nTags: Credit & Lending, Safety & Trust Scoring on Platforms\nCitations: 219\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:trust-safety:fraud-credit-claim:98:anomaly-detection-a-survey", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Anomaly Detection: A Survey\nAuthors: Varun Chandola, Arindam Banerjee, Vipin Kumar\nYear: 2009\nDescription: Comprehensive taxonomy covering classification, nearest-neighbor, clustering, and statistical approaches; 8,000+ citations.\nTags: Trust & Safety, Fraud, Credit and Claim Risk\nCitations: 10461\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:trust-safety:fraud-credit-claim:99:credit-card-fraud-credit-and-claim-risk-a-realistic-modeling-and-a-novel-learnin", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Credit Card Fraud, Credit and Claim Risk: A Realistic Modeling and a Novel Learning Strategy\nAuthors: Andrea Dal Pozzolo, Giacomo Boracchi, Olivier Caelen, Cesare Alippi, Gianluca Bontempi\nYear: 2018\nDescription: Addresses realistic fraud challenges: extreme class imbalance, concept drift, and delayed feedback loops.\nTags: Trust & Safety, Fraud, Credit and Claim Risk\nCitations: None\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:trust-safety:fraud-credit-claim:100:detecting-insurance-fraud-using-supervised-and-unsupervised-machine-learning", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Detecting Insurance Fraud Using Supervised and Unsupervised Machine Learning\nAuthors: Jens Debener, Volker Heinke, Johannes Kriebel\nYear: 2023\nDescription: Field experiment showing supervised and unsupervised methods are complements, not substitutes.\nTags: Trust & Safety, Fraud, Credit and Claim Risk\nCitations: 47\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:trust-safety:spam-abuse:101:fake-it-till-you-make-it-reputation-competition-and-yelp-review-fraud", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Fake It Till You Make It: Reputation, Competition, and Yelp Review Fraud\nAuthors: Michael Luca, Georgios Zervas\nYear: 2016\nDescription: First large-scale study of fake reviews; 16% of Yelp reviews flagged as fake, increasing with competition.\nTags: Trust & Safety, Spam & Abuse\nCitations: 1\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:trust-safety:spam-abuse:102:promotional-reviews-an-empirical-investigation-of-online-review-manipulation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Promotional Reviews: An Empirical Investigation of Online Review Manipulation\nAuthors: Dina Mayzlin, Yaniv Dover, Judith Chevalier\nYear: 2014\nDescription: Compares TripAdvisor vs Expedia reviews; finds review manipulation concentrated among independent hotels.\nTags: Trust & Safety, Spam & Abuse\nCitations: 855\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:trust-safety:privacy-data-misuse:103:the-economics-of-privacy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Economics of Privacy\nAuthors: Alessandro Acquisti, Curtis Taylor, Liad Wagman\nYear: 2016\nDescription: JEL survey covering market structure, price discrimination, and welfare effects of privacy regulation.\nTags: Trust & Safety, Privacy & Data Misuse\nCitations: 1057\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:logistics-operations:routing-dispatch:104:dynamic-pricing-and-matching-in-ride-hailing-platforms", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Dynamic Pricing and Matching in Ride-Hailing Platforms\nAuthors: Chiwei Yan, Helin Zhu, Nikita Korolko, Dawn Woodard\nYear: 2020\nDescription: Uber research on matching algorithms and dynamic pricing; batching and bipartite matching for real-time dispatch.\nTags: Logistics & Operations, Routing & Dispatch\nCitations: 288\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:logistics-operations:supply-chain-forecasting:105:deepar-probabilistic-forecasting-with-autoregressive-recurrent-networks", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks\nAuthors: David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski\nYear: 2020\nDescription: Foundational Amazon paper powering SageMaker and Amazon Forecast; ~15% accuracy improvement over classical methods via global RNN.\nTags: Logistics & Operations, Supply Chain Demand Forecasting\nCitations: 238\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:logistics-operations:supply-chain-forecasting:106:m5-accuracy-competition-results-findings-and-conclusions", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: M5 Accuracy Competition: Results, Findings, and Conclusions\nAuthors: Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos\nYear: 2022\nDescription: Landmark Walmart competition (42,840 time series) proving LightGBM ensembles outperform traditional statistical methods at retail scale.\nTags: Logistics & Operations, Supply Chain Demand Forecasting\nCitations: 366\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:logistics-operations:supply-chain-forecasting:107:temporal-fusion-transformers-for-interpretable-multi-horizon-time-series-forecas", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting\nAuthors: Bryan Lim, Sercan \u00d6. Ar\u0131k, Nicolas Loeff, Tomas Pfister\nYear: 2021\nDescription: Attention-based architecture achieving 7% lower P50, 9% lower P90 losses; combines performance with interpretable variable importance.\nTags: Logistics & Operations, Supply Chain Demand Forecasting\nCitations: 153\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:logistics-operations:capacity-planning:108:the-role-of-surge-pricing-on-a-service-platform-with-self-scheduling-capacity", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Role of Surge Pricing on a Service Platform with Self-Scheduling Capacity\nAuthors: Gerard Cachon, Kaitlin Daniels, Ruben Lobel\nYear: 2017\nDescription: Foundational theory showing surge pricing achieves near-optimal profits with self-scheduling workers; directly informs Uber/Lyft design.\nTags: Logistics & Operations, Capacity Planning\nCitations: 695\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:privacy:privacy-measurement:109:rappor-randomized-aggregatable-privacy-preserving-ordinal-response", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response\nAuthors: \u00dalfar Erlingsson, Vasyl Pihur, Aleksandra Korolova\nYear: 2014\nDescription: Foundation for privacy-preserving telemetry with local DP guarantees for aggregate statistics.\nTags: Privacy, Privacy-Preserving Measurement\nCitations: None\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:privacy:synthetic-data:110:semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data-", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data (PATE)\nAuthors: Nicolas Papernot, Mart\u00edn Abadi, \u00dalfar Erlingsson, Ian Goodfellow, Kunal Talwar\nYear: 2017\nDescription: PATE enables training on synthetic/unlabeled data with DP guarantees transferred from teacher ensemble.\nTags: Privacy, Synthetic Data\nCitations: 1\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:privacy:privacy-economics-regulation:111:privacy-regulation-and-online-advertising", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Privacy Regulation and Online Advertising\nAuthors: Avi Goldfarb, Catherine E. Tucker\nYear: 2011\nDescription: EU privacy directive reduced ad effectiveness by 65%; first major empirical study of privacy regulation impact.\nTags: Privacy, Privacy Economics & Regulation\nCitations: 3\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:spatial-geo:geospatial-demand:112:eta-prediction-with-graph-neural-networks-in-google-maps", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: ETA Prediction with Graph Neural Networks in Google Maps\nAuthors: Austin Derrow-Pinion et al. (Google/DeepMind)\nYear: 2021\nDescription: Production GNN that reduced negative ETA outcomes by 40%+ in cities like Sydney; deployed at scale.\nTags: Spatial & Geo, Geospatial Demand Modeling\nCitations: 184\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:spatial-geo:spatial-econometrics:113:estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimation and Inference of Heterogeneous Treatment Effects using Random Forests\nAuthors: Stefan Wager, Susan Athey\nYear: 2018\nDescription: Causal forests for heterogeneous treatment effects with valid confidence intervals; implemented in grf and EconML.\nTags: Spatial & Geo, Spatial Econometrics\nCitations: 2467\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:insurance-economics-insurtech:foundational-insurance-economics:114:equilibrium-in-competitive-insurance-markets-an-essay-on-the-economics-of-imperf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Equilibrium in Competitive Insurance Markets: An Essay on the Economics of Imperfect Information\nAuthors: Michael Rothschild, Joseph Stiglitz\nYear: 1976\nDescription: The most-cited paper in insurance economics. Demonstrates how insurers design contracts to induce self-selection by risk types and proves that pooling equilibria cannot survive competition. Nobel Prize work.\nTags: Insurance Economics, Adverse Selection, Contract Theory\nCitations: 4960\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:insurance-economics-insurtech:foundational-insurance-economics:115:uncertainty-and-the-welfare-economics-of-medical-care", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Uncertainty and the Welfare Economics of Medical Care\nAuthors: Kenneth J. Arrow\nYear: 1963\nDescription: The founding paper of health economics. Analyzes the special characteristics of medical care markets and introduces moral hazard as a fundamental problem in health insurance.\nTags: Health Economics, Moral Hazard, Information Asymmetry\nCitations: 4160\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:insurance-economics-insurtech:foundational-insurance-economics:116:health-insurance-and-the-demand-for-medical-care-evidence-from-a-randomized-expe", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Health Insurance and the Demand for Medical Care: Evidence from a Randomized Experiment\nAuthors: Willard G. Manning et al.\nYear: 1987\nDescription: The RAND Health Insurance Experiment\u2014gold-standard randomized evidence showing price elasticity of healthcare demand around -0.2, meaning cost-sharing reduces utilization by 25-30%.\nTags: Health Economics, Moral Hazard, Randomized Experiment\nCitations: 2083\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:clv-foundations:117:on-the-profitability-of-long-life-customers-in-a-noncontractual-setting", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: On the Profitability of Long-Life Customers in a Noncontractual Setting\nAuthors: Werner Reinartz, V. Kumar\nYear: 2000\nDescription: Challenges the assumption that long-tenure customers are always more profitable. Using catalog retailer data, shows that customer lifetime and profitability are not strongly correlated\u2014critical insight for customer selection.\nTags: MarTech & Customer Analytics, Customer Lifetime Value\nCitations: 1348\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:clv-foundations:118:a-customer-lifetime-value-framework-for-customer-selection-and-resource-allocati", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Customer Lifetime Value Framework for Customer Selection and Resource Allocation Strategy\nAuthors: Rajkumar Venkatesan, V. Kumar\nYear: 2004\nDescription: Demonstrates that marketing contacts influence CLV nonlinearly across channels. Develops a framework for selecting customers and allocating resources based on future CLV rather than past transactions.\nTags: MarTech & Customer Analytics, Customer Lifetime Value\nCitations: 922\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:btyd-models:119:counting-your-customers-who-are-they-and-what-will-they-do-next", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Counting Your Customers: Who Are They and What Will They Do Next?\nAuthors: David C. Schmittlein, Donald G. Morrison, Richard Colombo\nYear: 1987\nDescription: THE foundational BTYD paper introducing the Pareto/NBD model. Computes the probability a customer remains 'alive' based on recency and frequency, enabling all subsequent probabilistic customer-base analysis.\nTags: MarTech & Customer Analytics, BTYD Models\nCitations: 641\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:btyd-models:120:counting-your-customers-the-easy-way-an-alternative-to-the-pareto-nbd-model", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Counting Your Customers the Easy Way: An Alternative to the Pareto/NBD Model\nAuthors: Peter S. Fader, Bruce G.S. Hardie, Ka Lok Lee\nYear: 2005\nDescription: Develops the BG/NBD (Beta-Geometric/Negative Binomial Distribution) model\u2014vastly easier to implement than Pareto/NBD while achieving similar predictive accuracy. The workhorse model for non-contractual CLV estimation.\nTags: MarTech & Customer Analytics, BTYD Models\nCitations: 448\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:btyd-models:121:rfm-and-clv-using-iso-value-curves-for-customer-base-analysis", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: RFM and CLV: Using Iso-Value Curves for Customer Base Analysis\nAuthors: Peter S. Fader, Bruce G.S. Hardie, Ka Lok Lee\nYear: 2005\nDescription: Bridges traditional RFM (Recency, Frequency, Monetary) analysis with probabilistic CLV approaches. Shows how to use iso-value curves for customer segmentation that aligns with expected lifetime value.\nTags: MarTech & Customer Analytics, BTYD Models\nCitations: 552\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:btyd-models:122:probability-models-for-customer-base-analysis", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Probability Models for Customer-Base Analysis\nAuthors: Peter S. Fader, Bruce G.S. Hardie\nYear: 2009\nDescription: The definitive overview distinguishing contractual from non-contractual settings and discrete from continuous transaction timing. Essential framework for selecting the appropriate BTYD model for any business context.\nTags: MarTech & Customer Analytics, BTYD Models\nCitations: 187\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:btyd-models:123:customer-base-valuation-in-a-contractual-setting-the-perils-of-ignoring-heteroge", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Customer-Base Valuation in a Contractual Setting: The Perils of Ignoring Heterogeneity\nAuthors: Peter S. Fader, Bruce G.S. Hardie\nYear: 2010\nDescription: Extends BTYD models to subscription/contractual settings. Shows that ignoring customer heterogeneity leads to systematic overestimation of retention rates and customer value\u2014critical for SaaS and subscription businesses.\nTags: MarTech & Customer Analytics, BTYD Models\nCitations: 1\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:btyd-models:124:a-note-on-deriving-the-pareto-nbd-model-and-related-expressions", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Note on Deriving the Pareto/NBD Model and Related Expressions\nAuthors: Peter S. Fader, Bruce G.S. Hardie\nYear: 2005\nDescription: Step-by-step mathematical derivation of the Pareto/NBD model with detailed exposition of the likelihood function and conditional expectations. Essential reference for implementing BTYD models from scratch.\nTags: MarTech & Customer Analytics, BTYD Models\nCitations: 33\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:125:using-collaborative-filtering-to-weave-an-information-tapestry", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Collaborative Filtering to Weave an Information Tapestry\nAuthors: David Goldberg, David Nichols, Brian M. Oki, Douglas Terry\nYear: 1992\nDescription: THE paper that coined 'collaborative filtering.' Describes the Tapestry system at Xerox PARC where users could annotate documents and filter based on others' reactions\u2014the conceptual foundation of all modern recommendation systems.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 4025\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:126:grouplens-an-open-architecture-for-collaborative-filtering-of-netnews", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: GroupLens: An Open Architecture for Collaborative Filtering of Netnews\nAuthors: Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Peter Bergstrom, John Riedl\nYear: 1994\nDescription: Introduces automated collaborative filtering using Pearson correlation coefficients to predict ratings. The GroupLens project at University of Minnesota became the foundation for recommender systems research.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 4960\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:127:item-based-collaborative-filtering-recommendation-algorithms", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Item-Based Collaborative Filtering Recommendation Algorithms\nAuthors: Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl\nYear: 2001\nDescription: Demonstrates that item-item collaborative filtering dramatically outperforms user-based methods in both quality and scalability. This approach became the foundation of Amazon's recommendation engine.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 8793\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:128:matrix-factorization-techniques-for-recommender-systems", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Matrix Factorization Techniques for Recommender Systems\nAuthors: Yehuda Koren, Robert Bell, Chris Volinsky\nYear: 2009\nDescription: THE definitive paper on matrix factorization for recommendations, emerging from the Netflix Prize. Shows how to decompose the user-item matrix, handle implicit feedback, and incorporate temporal dynamics.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 11142\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:129:probabilistic-matrix-factorization", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Probabilistic Matrix Factorization\nAuthors: Ruslan Salakhutdinov, Andriy Mnih\nYear: 2008\nDescription: Introduces a probabilistic framework for matrix factorization that handles sparse data effectively through Bayesian priors. Achieves state-of-the-art performance on Netflix Prize and enables uncertainty quantification.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 3565\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:130:hybrid-recommender-systems-survey-and-experiments", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Hybrid Recommender Systems: Survey and Experiments\nAuthors: Robin Burke\nYear: 2002\nDescription: Comprehensive taxonomy of hybrid recommendation approaches: weighted, switching, mixed, feature combination, cascade, feature augmentation, and meta-level. Essential framework for combining collaborative, content-based, and knowledge-based methods.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 3635\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:recommendation-systems:131:the-netflix-recommender-system-algorithms-business-value-and-innovation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Netflix Recommender System: Algorithms, Business Value, and Innovation\nAuthors: Carlos A. Gomez-Uribe, Neil Hunt\nYear: 2015\nDescription: Netflix's official disclosure of their recommendation architecture. Estimates that personalization saves over $1 billion annually through reduced churn\u2014the definitive business case for recommendation system investment.\nTags: MarTech & Customer Analytics, Recommendation Systems\nCitations: 1243\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:churn-retention:132:retention-futility-targeting-high-risk-customers-might-be-ineffective", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Retention Futility: Targeting High-Risk Customers Might Be Ineffective\nAuthors: Eva Ascarza\nYear: 2018\nDescription: Paradigm-shifting paper showing that targeting highest-churn-risk customers for retention is often ineffective. Advocates targeting 'persuadable' customers\u2014those whose behavior changes with intervention\u2014rather than highest risk.\nTags: MarTech & Customer Analytics, Churn & Retention\nCitations: 232\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:churn-retention:133:predicting-customer-lifetime-duration-and-future-purchase-behavior", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Predicting Customer Lifetime Duration and Future Purchase Behavior\nAuthors: Greg M. Allenby, Robert P. Leone, Lichung Jen\nYear: 1999\nDescription: Early integration of customer lifetime duration prediction with purchase behavior modeling. Uses hazard models to jointly estimate when customers will leave and how much they'll spend while active.\nTags: MarTech & Customer Analytics, Churn & Retention\nCitations: 0\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:churn-retention:134:bagging-and-boosting-classification-trees-to-predict-churn", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Bagging and Boosting Classification Trees to Predict Churn\nAuthors: Aurelie Lemmens, Christophe Croux\nYear: 2006\nDescription: Systematic comparison of machine learning methods for churn prediction. Shows that ensemble methods (bagging, boosting) substantially outperform logistic regression\u2014establishing ML approaches for churn classification.\nTags: MarTech & Customer Analytics, Churn & Retention\nCitations: 402\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:churn-retention:135:a-generalized-framework-for-estimating-customer-lifetime-value-when-customer-lif", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Generalized Framework for Estimating Customer Lifetime Value When Customer Lifetimes Are Not Observed\nAuthors: Phillip E. Pfeifer, Robert L. Carraway\nYear: 2000\nDescription: Develops Markov chain framework for CLV estimation when customer departure isn't directly observed. Essential methodology for subscription businesses with involuntary churn and non-contractual settings.\nTags: MarTech & Customer Analytics, Churn & Retention\nCitations: 57\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:churn-retention:136:social-effects-on-customer-retention", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Social Effects on Customer Retention\nAuthors: Irit Nitzan, Barak Libai\nYear: 2011\nDescription: Demonstrates that customer churn has social network effects\u2014when one customer churns, connected customers are more likely to follow. Quantifies the 'defection contagion' effect for retention strategy.\nTags: MarTech & Customer Analytics, Churn & Retention\nCitations: 287\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:churn-retention:137:in-pursuit-of-enhanced-customer-retention-management-review-key-issues-and-futur", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: In Pursuit of Enhanced Customer Retention Management: Review, Key Issues, and Future Directions\nAuthors: Eva Ascarza, Scott A. Neslin, Oded Netzer, Zachery Anderson, Peter S. Fader, Sunil Gupta, Bruce G.S. Hardie, Aurelie Lemmens, Barak Libai, David Neal, Foster Provost, Rom Schrift\nYear: 2018\nDescription: Comprehensive review from leading researchers on customer retention management. Covers prediction, intervention design, and optimization\u2014synthesizing decades of research into actionable framework.\nTags: MarTech & Customer Analytics, Churn & Retention\nCitations: 162\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:mmm-attribution:138:aggregate-advertising-models-the-state-of-the-art", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Aggregate Advertising Models: The State of the Art\nAuthors: John D.C. Little\nYear: 1979\nDescription: THE foundational paper for marketing mix modeling. Establishes diminishing returns, carryover effects, and competitive interactions\u2014the theoretical underpinning of all modern MMM systems.\nTags: MarTech & Customer Analytics, Marketing Mix Modeling\nCitations: 367\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:mmm-attribution:139:sustained-spending-and-persistent-response-a-new-look-at-long-term-marketing-pro", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Sustained Spending and Persistent Response: A New Look at Long-Term Marketing Profitability\nAuthors: Marnik G. Dekimpe, Dominique M. Hanssens\nYear: 1999\nDescription: Pioneers distinguishing short-term versus long-term marketing effects using persistence modeling. Shows when marketing investments have permanent vs. temporary effects on sales\u2014essential for MMM interpretation.\nTags: MarTech & Customer Analytics, Marketing Mix Modeling\nCitations: 394\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:mmm-attribution:140:return-on-marketing-investment-romi-definition-uses-and-challenges", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Return on Marketing Investment (ROMI): Definition, Uses, and Challenges\nAuthors: Dominique M. Hanssens\nYear: 2024\nDescription: Proposes marginal ROMI as the unifying metric for marketing effectiveness measurement. Reviews common pitfalls in ROMI calculation and provides framework for managerial decision-making.\nTags: MarTech & Customer Analytics, Marketing Mix Modeling\nCitations: 0\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:mmm-attribution:141:data-driven-multi-touch-attribution-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Data-driven Multi-touch Attribution Models\nAuthors: Xuhui Shao, Lexin Li\nYear: 2011\nDescription: Technical foundation for algorithmic attribution. Develops probabilistic models for allocating conversion credit across marketing touchpoints\u2014moving beyond heuristic rules to data-driven attribution.\nTags: MarTech & Customer Analytics, Attribution\nCitations: 125\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:mmm-attribution:142:a-comparison-of-approaches-to-advertising-measurement-evidence-from-big-field-ex", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Comparison of Approaches to Advertising Measurement: Evidence from Big Field Experiments at Facebook\nAuthors: Brett R. Gordon, Florian Zettelmeyer, Neha Bhargava, Dan Chapsky\nYear: 2019\nDescription: Demonstrates significant biases in non-experimental advertising measurement methods through large Facebook experiments. Shows observational methods overestimate effects by 2-3x\u2014making the case for experimental measurement.\nTags: MarTech & Customer Analytics, Attribution\nCitations: 249\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:mmm-attribution:143:bayesian-methods-for-media-mix-modeling-with-carryover-and-shape-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Bayesian Methods for Media Mix Modeling with Carryover and Shape Effects\nAuthors: Yuxue Jin, Yueqing Wang, Yunting Sun, David Chan, Jim Koehler\nYear: 2017\nDescription: Google's Bayesian approach to media mix modeling. Handles adstock (carryover) effects and diminishing returns through hierarchical priors\u2014the methodology underlying modern MMM tools.\nTags: MarTech & Customer Analytics, Marketing Mix Modeling\nCitations: 13\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:personalization-email:144:the-effectiveness-of-triggered-email-marketing-in-addressing-browse-abandonments", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Effectiveness of Triggered Email Marketing in Addressing Browse Abandonments\nAuthors: Miguel Goic, Alejandro Rojas, Ignacio Saavedra\nYear: 2021\nDescription: First rigorous experimental evidence on browse abandonment email effectiveness. Quantifies the causal effect of triggered emails on conversion and identifies optimal timing and content strategies.\nTags: MarTech & Customer Analytics, Email Marketing\nCitations: 61\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:personalization-email:145:personalization-versus-privacy-an-empirical-examination-of-the-online-consumer-s", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Personalization versus Privacy: An Empirical Examination of the Online Consumer's Dilemma\nAuthors: Ramnath K. Chellappa, Raymond G. Sin\nYear: 2005\nDescription: Establishes the foundational trade-off model where personalization value must exceed privacy costs. Uses conjoint analysis to quantify consumer willingness to trade privacy for personalization benefits.\nTags: MarTech & Customer Analytics, Personalization\nCitations: 991\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:personalization-email:146:the-personalization-privacy-paradox-in-the-attention-economy", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Personalization-Privacy Paradox in the Attention Economy\nAuthors: J\u00e9r\u00e9my Cloarec\nYear: 2020\nDescription: Connects personalization-privacy trade-offs to the attention economy framework. Shows how platform incentives and attention scarcity affect consumer privacy decisions and personalization acceptance.\nTags: MarTech & Customer Analytics, Personalization\nCitations: 76\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:personalization-email:147:customization-of-online-advertising-the-role-of-intrusiveness", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Customization of Online Advertising: The Role of Intrusiveness\nAuthors: Asim Ansari, Carl F. Mela\nYear: 2003\nDescription: Early experimental evidence on personalized content effectiveness. Shows how to optimize email content and timing based on individual-level response models\u2014foundational for personalization systems.\nTags: MarTech & Customer Analytics, Personalization\nCitations: 258\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:personalization-email:148:dynamic-pricing-and-learning-historical-origins-current-research-and-new-directi", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Dynamic Pricing and Learning: Historical Origins, Current Research, and New Directions\nAuthors: Arnoud V. den Boer\nYear: 2015\nDescription: Comprehensive survey of dynamic pricing algorithms that learn optimal prices from demand data. Covers multi-armed bandits, Bayesian learning, and exploration-exploitation trade-offs in pricing.\nTags: MarTech & Customer Analytics, Dynamic Pricing\nCitations: 1\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:promotions-loyalty:149:decomposing-the-promotional-revenue-bump-for-loyalty-program-members-versus-nonm", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Decomposing the Promotional Revenue Bump for Loyalty Program Members versus Nonmembers\nAuthors: Harald J. van Heerde, Peter S.H. Leeflang, Dick R. Wittink\nYear: 2004\nDescription: Decomposes promotional effects into category expansion, brand switching, and purchase acceleration. Shows how loyalty program members respond differently to promotions than non-members.\nTags: MarTech & Customer Analytics, Promotions\nCitations: 97\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:promotions-loyalty:150:how-promotions-work", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: How Promotions Work\nAuthors: Robert C. Blattberg, Richard Briesch, Edward J. Fox\nYear: 1995\nDescription: Establishes the empirical generalizations about promotional effectiveness that still guide practice today. Documents patterns in deal elasticities, stockpiling, and cross-category effects.\nTags: MarTech & Customer Analytics, Promotions\nCitations: 636\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:promotions-loyalty:151:the-long-term-impact-of-loyalty-programs-on-consumer-purchase-behavior-and-loyal", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Long-Term Impact of Loyalty Programs on Consumer Purchase Behavior and Loyalty\nAuthors: Michael Lewis\nYear: 2004\nDescription: Develops the structural model for loyalty program ROI. Uses dynamic programming to separate true behavioral change from selection effects\u2014essential for evaluating loyalty program investments.\nTags: MarTech & Customer Analytics, Loyalty Programs\nCitations: 466\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:promotions-loyalty:152:do-customer-loyalty-programs-really-work", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Do Customer Loyalty Programs Really Work?\nAuthors: Grahame R. Dowling, Mark Uncles\nYear: 1997\nDescription: Essential critical perspective on loyalty program effectiveness. Argues that most programs create loyalty to the program, not the brand\u2014challenging assumptions about loyalty program ROI.\nTags: MarTech & Customer Analytics, Loyalty Programs\nCitations: 1039\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:martech-customer-analytics:promotions-loyalty:153:optimal-dynamic-pricing-of-inventories-with-stochastic-demand-over-finite-horizo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Optimal Dynamic Pricing of Inventories with Stochastic Demand over Finite Horizons\nAuthors: Guillermo Gallego, Garrett van Ryzin\nYear: 1994\nDescription: THE seminal paper for revenue management. Establishes theoretical foundations for dynamically pricing perishable inventory with uncertain demand\u2014underlying all modern pricing and promotion systems.\nTags: MarTech & Customer Analytics, Revenue Management\nCitations: 1558\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:llms-for-economic-research:154:generative-ai-for-economic-research-use-cases-and-implications-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Generative AI for Economic Research: Use Cases and Implications for Economists\nAuthors: Anton Korinek\nYear: 2023\nDescription: The foundational paper describing dozens of LLM use cases across six domains: ideation/feedback, writing, background research, data analysis, coding, and mathematical derivations. Published in Journal of Economic Literature.\nTags: AI for Economic Research, LLMs\nCitations: 150\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:llms-for-economic-research:155:ai-agents-for-economic-research", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: AI Agents for Economic Research\nAuthors: Anton Korinek\nYear: 2025\nDescription: NBER Working Paper 34202. Demystifies autonomous AI agents for multi-step research tasks, including 'vibe coding' with Claude Code and building research assistants with LangGraph.\nTags: AI for Economic Research, LLMs, AI Agents\nCitations: 0\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:llms-for-economic-research:156:large-language-models-an-applied-econometric-framework", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Large Language Models: An Applied Econometric Framework\nAuthors: Jens Ludwig, Sendhil Mullainathan, Ashesh Rambachan\nYear: 2024\nDescription: Framework for valid LLM use in empirical research. Addresses when and how LLMs can be appropriately used for econometric analysis.\nTags: AI for Economic Research, LLMs, Econometrics\nCitations: 5\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:llms-for-economic-research:157:large-language-models-a-primer-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Large Language Models: A Primer for Economists\nAuthors: Byeongwoo Kwon, Hyunju Lee, Patrick McSharry, Junmo Seong, Henry Wai-chung Yeung\nYear: 2024\nDescription: BIS Quarterly Review. 16-page primer with GitHub code for central banking applications of LLMs.\nTags: AI for Economic Research, LLMs, Central Banking\nCitations: 3\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:llms-for-economic-research:158:how-to-learn-and-teach-economics-with-large-language-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: How to Learn and Teach Economics with Large Language Models\nAuthors: Tyler Cowen, Alex Tabarrok\nYear: 2023\nDescription: Practical guide for GPT use in economics education from two prominent economists.\nTags: AI for Economic Research, LLMs, Education\nCitations: 45\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:synthetic-agents-homo-silicus:159:large-language-models-as-simulated-economic-agents-what-can-we-learn-from-homo-s", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?\nAuthors: John J. Horton, Apostolos Filippas, Benjamin S. Manning\nYear: 2023\nDescription: Foundational paper introducing homo silicus\u2014using LLMs as implicit computational models of humans. Replicates classic experiments from Charness & Rabin (2002), Kahneman et al. (1986), finding qualitatively similar results. Published in ACM EC'24.\nTags: AI for Economic Research, Synthetic Agents, Behavioral Economics\nCitations: 250\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:synthetic-agents-homo-silicus:160:automated-social-science-language-models-as-scientist-and-subjects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Automated Social Science: Language Models as Scientist and Subjects\nAuthors: Benjamin S. Manning, Kehang Zhu, John J. Horton\nYear: 2024\nDescription: NBER Working Paper 32381. Framework using LLMs to both generate research hypotheses and serve as experimental subjects.\nTags: AI for Economic Research, Synthetic Agents, Automation\nCitations: 20\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:synthetic-agents-homo-silicus:161:out-of-one-many-using-language-models-to-simulate-human-samples", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Out of One, Many: Using Language Models to Simulate Human Samples\nAuthors: Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua R. Gubler, Christopher Rytting, David Wingate\nYear: 2023\nDescription: Introduces 'silicon sampling'\u2014conditioning LLMs with demographic backstories to simulate subpopulation opinions. Develops 'algorithmic fidelity' concept measuring simulation accuracy. Published in Political Analysis.\nTags: AI for Economic Research, Synthetic Agents, Survey Methods\nCitations: 180\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:synthetic-agents-homo-silicus:162:synthetic-replacements-for-human-survey-data-the-perils-of-large-language-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Synthetic Replacements for Human Survey Data? The Perils of Large Language Models\nAuthors: James Bisbee, Joshua D. Clinton, Cassy Dorff, Brenton Kenkel, Jennifer Larson\nYear: 2024\nDescription: Critical validation study: 48% of regression coefficients differ significantly from human data; 32% sign flips. Important cautionary findings.\nTags: AI for Economic Research, Synthetic Agents, Validation\nCitations: 35\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:synthetic-agents-homo-silicus:163:large-language-models-empowered-agent-based-modeling-and-simulation-a-survey-and", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives\nAuthors: Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, Fengli Xu, Yong Li\nYear: 2024\nDescription: Comprehensive survey covering agent design, environment construction, and personalization for LLM-based simulations. Published in Nature Humanities and Social Sciences Communications.\nTags: AI for Economic Research, Agent-Based Modeling, LLMs\nCitations: 85\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:ml-methods-for-economists:164:machine-learning-an-applied-econometric-approach", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Machine Learning: An Applied Econometric Approach\nAuthors: Sendhil Mullainathan, Jann Spiess\nYear: 2017\nDescription: THE foundational paper explaining ML's role in economics: ML solves prediction problems while economics focuses on parameter estimation. Over 1,500 citations. Published in Journal of Economic Perspectives.\nTags: Machine Learning, Econometrics\nCitations: 1500\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:ml-methods-for-economists:165:machine-learning-methods-that-economists-should-know-about", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Machine Learning Methods That Economists Should Know About\nAuthors: Susan Athey, Guido W. Imbens\nYear: 2019\nDescription: Comprehensive review including supervised/unsupervised learning, matrix completion, and ML-econometrics methods. Published in Annual Review of Economics.\nTags: Machine Learning, Econometrics\nCitations: 1200\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:ml-methods-for-economists:166:deep-learning-for-economists", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Deep Learning for Economists\nAuthors: Melissa Dell\nYear: 2025\nDescription: Comprehensive tutorial on classifiers, regression models, generative AI, and embedding models with demo notebooks. Published in Journal of Economic Literature. Companion site: econdl.github.io\nTags: Deep Learning, Machine Learning, Tutorial\nCitations: 15\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:ml-methods-for-economists:167:machine-learning-as-a-tool-for-hypothesis-generation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Machine Learning as a Tool for Hypothesis Generation\nAuthors: Jens Ludwig, Sendhil Mullainathan\nYear: 2024\nDescription: Systematic ML procedure for generating novel hypotheses. Application: defendant mugshots explain ~50% of predictable variation in judge decisions. Published in Quarterly Journal of Economics.\nTags: Machine Learning, Hypothesis Generation\nCitations: 50\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:causal-machine-learning:168:recursive-partitioning-for-heterogeneous-causal-effects", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Recursive Partitioning for Heterogeneous Causal Effects\nAuthors: Susan Athey, Guido Imbens\nYear: 2016\nDescription: Introduces 'honest' causal trees using sample splitting. Published in PNAS.\nTags: Causal Inference, Machine Learning, Heterogeneous Effects\nCitations: 1800\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:causal-machine-learning:169:estimation-and-inference-of-heterogeneous-treatment-effects-using-random-forests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Estimation and Inference of Heterogeneous Treatment Effects using Random Forests\nAuthors: Stefan Wager, Susan Athey\nYear: 2018\nDescription: Develops causal forests with asymptotic theory and valid confidence intervals. Published in JASA.\nTags: Causal Inference, Machine Learning, Random Forests\nCitations: 2500\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:causal-machine-learning:170:generalized-random-forests", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Generalized Random Forests\nAuthors: Susan Athey, Julie Tibshirani, Stefan Wager\nYear: 2019\nDescription: Framework extending random forests to solve local moment equations. Published in Annals of Statistics.\nTags: Causal Inference, Machine Learning, Random Forests\nCitations: 1100\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:causal-machine-learning:171:double-debiased-machine-learning-for-treatment-and-structural-parameters", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Double/Debiased Machine Learning for Treatment and Structural Parameters\nAuthors: Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins\nYear: 2018\nDescription: Establishes Double ML using Neyman orthogonal scores and cross-fitting. Published in The Econometrics Journal.\nTags: Causal Inference, Machine Learning, Double ML\nCitations: 2200\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:text-as-data:172:text-as-data", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Text as Data\nAuthors: Matthew Gentzkow, Bryan Kelly, Matt Taddy\nYear: 2019\nDescription: THE seminal survey providing introduction to text-as-data methods in economics. Published in Journal of Economic Literature.\nTags: NLP, Text Analysis, Econometrics\nCitations: 900\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:text-as-data:173:measuring-group-differences-in-high-dimensional-choices-method-and-application-t", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Measuring Group Differences in High-Dimensional Choices: Method and Application to Congressional Speech\nAuthors: Matthew Gentzkow, Jesse M. Shapiro, Matt Taddy\nYear: 2019\nDescription: ML methodology for measuring partisanship in congressional speech (1873-2016). Published in Econometrica.\nTags: NLP, Text Analysis, Political Economy\nCitations: 400\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:text-as-data:174:text-algorithms-in-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Text Algorithms in Economics\nAuthors: Elliott Ash, Stephen Hansen\nYear: 2023\nDescription: Overview covering word embeddings, topic models, and transformers for economics research. Published in Annual Review of Economics.\nTags: NLP, Text Analysis, Machine Learning\nCitations: 75\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:satellite-imagery-computer-vision:175:measuring-economic-growth-from-outer-space", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Measuring Economic Growth from Outer Space\nAuthors: J. Vernon Henderson, Adam Storeygard, David N. Weil\nYear: 2012\nDescription: Foundational paper using nighttime lights to proxy GDP. For poor-data countries, optimal growth estimate weights lights equally with official statistics. Published in American Economic Review.\nTags: Computer Vision, Satellite Imagery, Development\nCitations: 2800\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:satellite-imagery-computer-vision:176:combining-satellite-imagery-and-machine-learning-to-predict-poverty", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Combining Satellite Imagery and Machine Learning to Predict Poverty\nAuthors: Neal Jean, Marshall Burke, Michael Xie, W. Matthew Davis, David B. Lobell, Stefano Ermon\nYear: 2016\nDescription: Landmark study: CNNs trained on satellite imagery explain 75% of variation in local economic outcomes across 5 African countries. Published in Science.\nTags: Computer Vision, Deep Learning, Poverty\nCitations: 2100\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:satellite-imagery-computer-vision:177:using-publicly-available-satellite-imagery-and-deep-learning-to-understand-econo", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Publicly Available Satellite Imagery and Deep Learning to Understand Economic Well-Being in Africa\nAuthors: Christopher Yeh, Anthony Perez, Anne Driscoll, George Azzari, Zhongyi Tang, David Lobell, Stefano Ermon, Marshall Burke\nYear: 2020\nDescription: Models predict 70% of variation in village wealth across held-out African countries. Published in Nature Communications.\nTags: Computer Vision, Deep Learning, Development\nCitations: 450\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:ai-for-economic-research:satellite-imagery-computer-vision:178:using-deep-learning-and-google-street-view-to-estimate-the-demographic-makeup-of", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Using Deep Learning and Google Street View to Estimate the Demographic Makeup of Neighborhoods across the United States\nAuthors: Timnit Gebru, Jonathan Krause, Yilun Wang, Duyun Chen, Jia Deng, Erez Lieberman Aiden, Li Fei-Fei\nYear: 2017\nDescription: Car detection infers income, race, voting patterns from 50M Google Street View images. Published in PNAS.\nTags: Computer Vision, Deep Learning, Demographics\nCitations: 650\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:179:agent-based-computational-economics-a-constructive-approach-to-economic-theory", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Agent-Based Computational Economics: A Constructive Approach to Economic Theory\nAuthors: Leigh Tesfatsion\nYear: 2006\nDescription: Foundational survey establishing ACE methodology. Defines agent-based computational economics as the computational study of economies modeled as evolving systems of autonomous interacting agents. Published in Handbook of Computational Economics Vol. 2.\nTags: Agent-Based Modeling, Computational Economics, Survey\nCitations: 2100\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:180:agent-based-modeling-in-economics-and-finance-past-present-and-future", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Agent-Based Modeling in Economics and Finance: Past, Present, and Future\nAuthors: Robert Axtell, J. Doyne Farmer\nYear: 2025\nDescription: Definitive 90-page survey in Journal of Economic Literature reviewing 30 years of ABM in economics. Covers finance, industrial organization, macroeconomics, and policy applications. Essential reading for the field.\nTags: Agent-Based Modeling, Survey, Economic Theory\nCitations: 50\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:181:artificial-economic-life-a-simple-model-of-a-stockmarket", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Artificial Economic Life: A Simple Model of a Stockmarket\nAuthors: W. Brian Arthur, John H. Holland, Blake LeBaron, Richard Palmer, Paul Tayler\nYear: 1997\nDescription: The Santa Fe Artificial Stock Market\u2014foundational heterogeneous agent financial model. Shows how bubbles and crashes emerge from adaptive learning traders. Seminal work in agent-based finance.\nTags: Agent-Based Modeling, Financial Markets, Complexity\nCitations: 950\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:182:the-economy-needs-agent-based-modelling", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Economy Needs Agent-Based Modelling\nAuthors: J. Doyne Farmer, Duncan Foley\nYear: 2009\nDescription: Nature commentary arguing for ABM in economic policy. Critiques DSGE models' failure to predict 2008 crisis; calls for bottom-up agent-based approaches to model systemic risk.\nTags: Agent-Based Modeling, Policy, Financial Crisis\nCitations: 1200\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:183:leverage-causes-fat-tails-and-clustered-volatility", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Leverage Causes Fat Tails and Clustered Volatility\nAuthors: Stefan Thurner, J. Doyne Farmer, John Geanakoplos\nYear: 2012\nDescription: Agent-based explanation of financial market fat tails and volatility clustering. Shows leveraged agents create price fluctuations 10x larger than fundamentals. Published in Quantitative Finance.\nTags: Agent-Based Modeling, Financial Markets, Leverage\nCitations: 450\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:184:mesa-an-agent-based-modeling-framework", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Mesa: An Agent-Based Modeling Framework\nAuthors: Jackie Kazil, David Masad, Andrew Crooks\nYear: 2020\nDescription: Introduces Mesa, the leading open-source Python ABM framework. Describes modular architecture with spatial grids, agent schedulers, and data collection. Published in JOSS.\nTags: Agent-Based Modeling, Python, Software\nCitations: 380\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:185:econ-ark-and-hark-open-source-tools-for-computational-economics", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Econ-ARK and HARK: Open-Source Tools for Computational Economics\nAuthors: Christopher D. Carroll, Alexander M. Kaufman, Jacqueline L. Kazil, Nathan M. Palmer, Matthew N. White\nYear: 2018\nDescription: Describes Econ-ARK ecosystem and HARK toolkit for heterogeneous agent modeling. NumFOCUS-sponsored project implementing Aiyagari, buffer-stock, and lifecycle models.\nTags: Heterogeneous Agents, Macroeconomics, Software\nCitations: 120\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:agent-based-modeling:186:a-standard-protocol-for-describing-individual-based-and-agent-based-models", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: A Standard Protocol for Describing Individual-Based and Agent-Based Models\nAuthors: Volker Grimm, Uta Berger, Finn Bastiansen, Sigrunn Eliassen, Vincent Ginot, Jarl Giske, John Goss-Custard, Tamara Grand, Simone K. Heinz, Geir Huse, Andreas Huth, Jane U. Jepsen, Christian J\u00f8rgensen, Wolf M. Mooij, Birgit M\u00fcller, Guy Pe'er, Cyril Piou, Steven F. Railsback, Andrew M. Robbins, Martha M. Robbins, Eva Rossmanith, Nadja R\u00fcger, Espen Strand, Sami Souissi, Richard A. Stillman, Rune Vab\u00f8, Ute Visser, Donald L. DeAngelis\nYear: 2006\nDescription: The ODD (Overview, Design concepts, Details) protocol for describing ABMs. Standard framework for model documentation adopted across ecology and social simulation.\nTags: Agent-Based Modeling, Methodology, Documentation\nCitations: 4500\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:synthetic-data-generation:187:modeling-tabular-data-using-conditional-gan", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Modeling Tabular Data using Conditional GAN\nAuthors: Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan Veeramachaneni\nYear: 2019\nDescription: Introduces CTGAN using mode-specific normalization and conditional generator for tabular data synthesis. Handles mixed discrete/continuous columns. Published at NeurIPS.\nTags: Synthetic Data, GAN, Deep Learning\nCitations: 1500\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:synthetic-data-generation:188:datasynthesizer-privacy-preserving-synthetic-datasets", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: DataSynthesizer: Privacy-Preserving Synthetic Datasets\nAuthors: Haoyue Ping, Julia Stoyanovich, Bill Howe\nYear: 2017\nDescription: Introduces DataSynthesizer for generating synthetic data with differential privacy using Bayesian networks. Three modes: random, independent attributes, and correlated attributes.\nTags: Synthetic Data, Privacy, Differential Privacy\nCitations: 320\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:synthetic-data-generation:189:synthpop-bespoke-creation-of-synthetic-data-in-r", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: synthpop: Bespoke Creation of Synthetic Data in R\nAuthors: Beata Nowok, Gillian M. Raab, Chris Dibben\nYear: 2016\nDescription: Introduces synthpop R package using CART-based synthesis. Produces realistic synthetic data preserving statistical relationships. Published in Journal of Statistical Software.\nTags: Synthetic Data, R, CART\nCitations: 650\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:synthetic-data-generation:190:the-synthetic-data-vault", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The Synthetic Data Vault\nAuthors: Neha Patki, Roy Wedge, Kalyan Veeramachaneni\nYear: 2016\nDescription: Introduces SDV system for synthesizing relational databases while preserving referential integrity. Uses copulas and deep learning for multi-table synthesis.\nTags: Synthetic Data, Relational Data, Copulas\nCitations: 250\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:synthetic-data-generation:191:pate-gan-generating-synthetic-data-with-differential-privacy-guarantees", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees\nAuthors: James Jordon, Jinsung Yoon, Mihaela van der Schaar\nYear: 2019\nDescription: Combines Private Aggregation of Teacher Ensembles (PATE) with GANs for differentially private synthetic data. Provides formal privacy guarantees with strong utility.\nTags: Synthetic Data, Differential Privacy, GAN\nCitations: 450\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:synthetic-data-generation:192:anonymeter-a-python-library-for-privacy-risk-assessment", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Anonymeter: A Python Library for Privacy Risk Assessment\nAuthors: Lucas Giomi, Eleonora Botta, Marco Esposito, Julien Herzen, Michael Grossniklaus\nYear: 2022\nDescription: Framework for GDPR-aligned privacy risk quantification. Measures singling out, linkability, and inference risks for synthetic datasets.\nTags: Privacy, GDPR, Risk Assessment\nCitations: 45\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:mechanism-design-rl:193:optimal-auctions-through-deep-learning", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Optimal Auctions through Deep Learning\nAuthors: Paul D\u00fctting, Zhe Feng, Harikrishna Narasimhan, David C. Parkes, Sai Srivatsa Ravindranath\nYear: 2019\nDescription: Introduces RegretNet\u2014neural network architecture that learns approximately revenue-optimal auctions. First general-purpose approach to automated mechanism design. Published at ICML, later CACM 2020.\nTags: Mechanism Design, Deep Learning, Auctions\nCitations: 580\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:mechanism-design-rl:194:the-ai-economist-taxation-policy-design-via-two-level-deep-reinforcement-learnin", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: The AI Economist: Taxation Policy Design via Two-Level Deep Reinforcement Learning\nAuthors: Stephan Zheng, Alexander Trott, Sunil Srinivasa, David C. Parkes, Richard Socher\nYear: 2022\nDescription: Two-level RL for optimal taxation: agents optimize labor/trade, social planner optimizes tax policy. Finds policies outperforming baselines by 16% on equality-productivity. Published in Science Advances.\nTags: Mechanism Design, Taxation, Reinforcement Learning\nCitations: 320\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:mechanism-design-rl:195:multi-agent-reinforcement-learning-in-sequential-social-dilemmas", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Multi-Agent Reinforcement Learning in Sequential Social Dilemmas\nAuthors: Joel Z. Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, Thore Graepel\nYear: 2017\nDescription: Foundational work on multi-agent RL in games with mixed cooperative/competitive incentives. Introduces sequential social dilemmas; shows cooperation emergence depends on environment structure.\nTags: Multi-Agent RL, Game Theory, Cooperation\nCitations: 850\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:mechanism-design-rl:196:deep-reinforcement-learning-for-optimal-execution", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Deep Reinforcement Learning for Optimal Execution\nAuthors: Yong Lin, Zhe Feng, Lihong Li, Marcus Zahradka, Harikrishna Narasimhan, David C. Parkes\nYear: 2020\nDescription: Applies deep RL to optimal order execution problem. Learns execution policies that outperform TWAP/VWAP benchmarks on real market data.\nTags: Reinforcement Learning, Trading, Execution\nCitations: 180\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:mechanism-design-rl:197:discovering-algorithmic-pricing-in-practice-a-framework-for-learning-based-collu", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Discovering Algorithmic Pricing in Practice: A Framework for Learning-Based Collusion\nAuthors: Timo Becker, Zhi Chen, Silvio Micali, Zhiyi Huang\nYear: 2023\nDescription: Studies emergence of tacit collusion in RL-based pricing algorithms. Shows Q-learning agents can learn supra-competitive prices without explicit coordination.\nTags: Algorithmic Pricing, Collusion, Antitrust\nCitations: 95\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:market-simulation:198:abides-towards-high-fidelity-multi-agent-market-simulation", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: ABIDES: Towards High-Fidelity Multi-Agent Market Simulation\nAuthors: David Byrd, Maria Hybinette, Tucker Hybinette Balch\nYear: 2020\nDescription: Introduces ABIDES (Agent-Based Interactive Discrete Event Simulation) from JPMorgan. NASDAQ-like exchange with ZI, momentum, and market maker agents. Published at AAMAS.\nTags: Market Simulation, Agent-Based, Order Book\nCitations: 180\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:market-simulation:199:get-real-realism-metrics-for-robust-limit-order-book-market-simulations", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Get Real: Realism Metrics for Robust Limit Order Book Market Simulations\nAuthors: Svitlana Vyetrenko, David Byrd, Nick Petosa, Mahmoud Mahfouz, Danial Dervovic, Manuela Veloso, Tucker Hybinette Balch\nYear: 2020\nDescription: Establishes stylized facts benchmarks for evaluating LOB simulation realism. Proposes metrics for fat tails, volatility clustering, and bid-ask spread dynamics.\nTags: Market Simulation, Stylized Facts, Validation\nCitations: 85\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:market-simulation:200:internet-advertising-and-the-generalized-second-price-auction", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Internet Advertising and the Generalized Second-Price Auction\nAuthors: Benjamin Edelman, Michael Ostrovsky, Michael Schwarz\nYear: 2007\nDescription: Analyzes the Generalized Second-Price (GSP) auction used by Google and Yahoo for sponsored search. Shows GSP has efficient Nash equilibria equivalent to VCG outcomes. Published in AER.\nTags: Auctions, Advertising, Mechanism Design\nCitations: 3800\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:market-simulation:201:limit-order-book-simulation-methods-a-review", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: Limit Order Book Simulation Methods: A Review\nAuthors: Rama Cont, Arseniy Kukanov, Sasha Stoikov\nYear: 2023\nDescription: Comprehensive review of LOB simulation methods: order flow models, agent-based approaches, and deep learning. Covers validation metrics and calibration techniques.\nTags: Market Simulation, Survey, Order Book\nCitations: 25\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
{"custom_id": "paper:simulation-synthetic-data:market-simulation:202:auctiongym-simulating-online-advertising-auctions", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a metadata enrichment assistant. Return only valid JSON. Never fabricate information - use null or empty arrays when data is not available."}, {"role": "user", "content": "You're enriching academic paper metadata for tech-econ.org, a curated library for tech economists.\n\nPAPER:\nTitle: AuctionGym: Simulating Online Advertising Auctions\nAuthors: Martin Mladenov, Sloan Nietert, Kunhe Yang, Aranyak Mehta, Christos Tzamos, Craig Boutilier\nYear: 2022\nDescription: Amazon's ad auction simulator for training RL bidding agents. Supports first/second-price auctions with realistic features. Best Paper at AdKDD 2022.\nTags: Auctions, Advertising, Reinforcement Learning\nCitations: 45\n\nReturn JSON:\n{\n  \"difficulty\": \"beginner|intermediate|advanced\",\n  \"prerequisites\": [\"specific-method-1\", \"specific-concept-2\"],\n  \"topic_tags\": [\"method-tag\", \"domain-tag\", \"application-tag\"],\n  \"summary\": \"2-3 sentences: What problem does this solve? What's the main contribution?\",\n  \"audience\": [\"Early-PhD\", \"Junior-DS\", \"Mid-DS\", \"Senior-DS\", \"Curious-browser\"],\n  \"synthetic_questions\": [\"6-8 natural search queries to find this paper\"],\n  \"use_cases\": [\"2-3 practical scenarios where you'd apply this\"],\n  \"methodology_tags\": [\"difference-in-differences\", \"instrumental-variables\", etc.],\n  \"key_findings\": \"One sentence: main result if mentioned in description, or empty string\",\n  \"research_questions\": [\"What question does this answer?\"],\n  \"datasets_used\": [\"Only if explicitly mentioned in description, else empty array\"],\n  \"implements_method\": \"Name of new method if this paper introduces one, else null\",\n  \"builds_on\": [\"Only well-known foundational papers if clearly referenced, else empty\"],\n  \"embedding_text\": \"500-1000 word dense description for semantic search (see instructions below)\"\n}\n\nRULES:\n- METHODOLOGY_TAGS: Use hyphenated method names (difference-in-differences, regression-discontinuity)\n- PREREQUISITES: Actual methods/concepts needed (bayesian-inference, panel-data)\n- SYNTHETIC_QUESTIONS: Natural queries like \"how to estimate treatment effects\"\n- KEY_FINDINGS: Only include if explicitly stated in description; leave empty if not mentioned\n\nCRITICAL: Only include information that can be reasonably inferred from the provided data.\n- If you cannot determine a field from the given information, use null or empty array []\n- DO NOT invent datasets, paper references, specific statistics, or tool names\n- DO NOT guess temporal coverage, geographic scope, or size metrics\n- For implements_paper/builds_on: Only include if explicitly mentioned or very well-known\n- For synthetic_questions: Base these on the actual description, not assumptions\n- When uncertain, prefer empty/null over fabricated data\n\n\n\nEMBEDDING_TEXT: Generate a rich, dense description (500-1000 words) for semantic search.\nWrite as continuous prose, keyword-rich, technically accurate.\nDo NOT invent specific paper names, dataset names, or tool names not in the source.\n\nFor this PAPER, include:\n- Research problem and motivation\n- Key methodology/approach in technical detail\n- Main findings and contributions\n- Econometric/statistical techniques used\n- Data requirements and assumptions\n- Limitations and caveats\n- Related research areas this connects to\n- Practical implications for applied researchers\n- When/why a practitioner would cite or apply this paper\n\n\nJSON only, no markdown."}], "max_tokens": 2000, "temperature": 0.3, "response_format": {"type": "json_object"}}}
